[
["welcome.html", "Tech Trainings - From Excel to R 1 Welcome 1.1 Agenda 1.2 Download and Install R 1.3 Download and Install RStudio 1.4 Download workshop data", " Tech Trainings - From Excel to R James Simkins 2020-07-09 1 Welcome Hello! Welcome to Tech Trainings - From Excel to R. We’re here to enhance the productivity of your business by ditching Excel and employing R. Our tutorials are focused and designed for employees currently working. R is currently ranked as the 7th most popular language in the world - and with good reason! We’ll dive into why R is ranked so high and how it can benefit you and your business. This intro to R course is designed to teach R to businesses and employees who frequently use Excel for day-to-day operations. Few businesses around the world leverage the amazing features of R and we’re here to teach these skills. To put it bluntly, R saves you and your employees a ton of time. We’ve seen users cut down daily 2-3 hour tasks in Excel into 2-3 minutes after some basic introduction to R. In this case, R saved this individual employee 750 hours per year - allowing employee time to be used towards more creative problem-solving endeavors. This is a concentrated, fast-paced course designed to improve business efficiency, cut down tedious tasks, and increase the creative time spent by employees. Most online R tutorials are far too broad and can leave a student frustrated at the vast abilities of R. R can be used to accomplish a great deal, but instead of showing off what R can do, we discuss and teach select skills that can be used to improve day-to-day business efficiency immediately. We’re not here to waste your time and overwhelm our students like other R workshops. This concentrated course follows a design of specific problem solving. We present common business practices often handled using Excel and show an employee can use R to accomplish the same task at a faster pace. The workshop is split into 5 days with assignments due each day. This course was developed by James Simkins who has taught multiple programming courses at the University of Delaware. 1.1 Agenda This course is designed to be a 5 day course intended to teach R to Excel Users. The intended time per day is 2-3 hours. Day Focus 1 Overview 2 Avacado Tutorial 1 3 Avacado Tutorial 2 4 Visa Tutorial 1 5 Visa Tutorial 2 Before the training, please do the following (10 minutes). All software is free and trusted. 1.2 Download and Install R Navigate to the R website: https://cloud.r-project.org/ Click Download for your Operating System (Windows, Mac OSx, or Linux - if you don’t have a MacBook, then you’re using Windows most likely) Click the most recent R version to download. Install the downloaded application as you would with any other application on your computer. 1.3 Download and Install RStudio Navigate to the RStudio Website: http://www.rstudio.com/download Click Download under RStudio Desktop Free This website detects your operating system, allowing you to just click download again. Note that if it doesn’t automatically detect just select the download next to your operating system below this Note that you may be asked to install command line developer tools if you’re using a Mac - select Yes. Install the downloaded application as you normally would on your computer. 1.4 Download workshop data Navigate to the database - https://github.com/jsimkins2/dataforge Click on Code - then click download as zip "],
["overview.html", "2 Overview 2.1 What is R? 2.2 Reasons to love R 2.3 Guiding Principles", " 2 Overview 2.1 What is R? R is an open-source (aka free) programming language. It was initially created for statistical operations in the 1990s but has since expanded greatly and can now be used to accomplish almost any data related task. Using R involves writing a script. A script is just an R document that performs some sort of analysis / operation / image creation. Writing code and generating an R script is done completely via typing as opposed to pointing and clicking. In this workshop we’ll learn how to write an R script and use it to perform data analysis. The purpose of this workshop is to teach working professionals how to use R for tasks they’d normally use Excel for. Excel is a powerful tool and is great for a variety of uses, but when it comes to crunching data, R will greatly improve the speed at which these tasks can be done. Furthermore, with R, mundane &amp; tedious tasks can be automated. When you write a script in R for a recurring task such as calculating a monthly budget, all one needs to do each month is provide the routine with a new dataset to crunch the numbers. Below are examples of why we use R. 2.2 Reasons to love R Attribute Reason Speed Spreadsheets that take 1 hour of computer calculation time in Excel take less than a second in R Capacity Excel can handle thousands of records, R can handle millions Risk Reduction Excel requires process notes, manual steps, copy/paste values, fill down, etc. After writing a single R script, R is auditable and reproducible within milliseconds - without any alterations to your original data. For example, if you are working with a dataset that multiple people are using, you can load this dataset in R and perform the tasks that you need without making any changes to the original dataset. Visualizations R is capable to create high quality visualizations and also has the capacity to create interactive visualizations that can easiliy be shared. Plots or images can easily be exported to PNG, JPEG, or even web-based interactive dashboards that can be hosted on a webpage Collaboration R script sharing is much safer than in Excel. As mentioned above, a team using the same data input file but performing different tasks on it can do so without editing the data input file for everyone else. Data output can also be shared without the concern of a colleague editing the file output. RStudio connect or Github are also popular free track all changes that take place between R script files. Price R is completely free! Yes…every bit of it! 2.3 Guiding Principles Comment, comment, comment. A comment is a brief note on what you were doing when you wrote a line of code. For example, if you write some R code that edits part of a dataframe (R’s version of an Excel Spreadsheet), comment what you were thinking here and why you did it this way. Once you become comfortable coding in R, you’ll be able to churn out new R scripts at a faster rate. It’s very important that you comment on what you’re doing at each step in the script so if you need to look back on something you wrote you can reference what you were doing there. A comment in R is declared using the pound symbol (#). Keep raw data raw. An advantage of R is being able to read in an original spreadsheet and output a new spreadsheet as a separate file. In other words, when you read in a dataset (for example, tv_shows.csv) and make changes to this file, do not save it was tv_shows.csv - thus overwriting the file. Instead, name it something like tv_shows_edited.csv. Also, notice how we use underscores (_) in between words of a filename - this is good practice that should be replicated (spaces are bad, see 4) When in doubt, Google your R question - look for StackOverflow links. StackOverflow is a web-forum where programmers can post questions for help. This is an incredible tool that even advanced programmers and developers use daily. There are other helpful forums out there - StackOverflow is the most popular. Spaces in variable/file names are BAD. A variable is an object or column that you create in R. For example, if you have a list of student names (student_names = list(&quot;John&quot;, &quot;Peter&quot;, &quot;Sebastian&quot;), the variable here would be student_names. Let’s get into the habit of using underscores ’_’ or dashes ‘-’ or periods ‘.’ to separate words instead of spaces. From the computers side of variable name storage, it’s much safe to declare a variable name such as data_file as opposed to data file Let’s get coding! "],
["r-rstudio.html", "3 R &amp; RStudio 3.1 Open RStudio 3.2 R Studio Layout 3.3 Installing and Using Packages 3.4 Loading the installed packages into R 3.5 Running Code 3.6 Checkpoint - Writing your first R code 3.7 Explanation - Writing your first R code", " 3 R &amp; RStudio By now you’ve downloaded R and RStudio and you’re probably wondering, why do I need to download both? R is that programming language that is running on your computer. RStudio is what we call an Indegrated Development Environment (IDE) - this is a technical term for a pretty application that’s all dressed up on the surface but underneath is really crunching some numbers (using R) at serious speeds. RStudio is the application we’ll be using. It is our Microsoft Excel. RStudio runs R in the background for us and gives us information and a nice, user-friendly layout. Let’s open RStudio and get familiar with it. 3.1 Open RStudio Navigate to your applications folder on your computer. Launch RStudio. When you open it for the first time, you should see this. This is RStudio. When you open it for the first time, we’ll need to open a new RScript to begin coding. Open new R Script To open a new R Script, we select the blankpage with green plus icon and select R Script from the menu. This opens up the new R script and we can begin coding in R. Now that we have the R Script open, you’ll notice 4 quadrants. Let’s run through what those quadrants are. 3.2 R Studio Layout Now let’s describe what’s going on here in a little more detail. R Script - This is your canvas. This is where we write and edit our code. A lot of trial and error goes on here. R Console - This is where you run your code. When we talk about running code, we mean we’re telling R to execute the code we’ve written in the R Script. R Console is the place inside RStudio where we are using the R programming language. Variable Environment - This area keeps track of your variables, data tables, filenames, etc. Anything that you run in R that has a name will be stored here. Imagine the Variable Environment to be your closet - every time you make/buy a new sweater, the sweater goes in the closet. We can select data tables to view from this list here. Files/Plots/Help - In this quadrant, we can toggle through files on our computer (we can view where your files are stored), view plots/visualizations that we’re creating in R (whenever you create a plot in R it is output here first), search for help and descriptions of R functions (there’s descriptions on every function you’ll use in R - they can all be loaded here in the help tab), and more. 3.3 Installing and Using Packages To use a function in R that performs a task (such as plotting, statistical analysis, etc.), we must first load the package into our R session. When we use Microsoft Excel, nearly all the functions you can use with it are available in the toolbar at the top of the page. In R, however, you’ll need to load in the packages you’d like to use. Once the package is loaded, R will recognize any functions you call that are part of that package. In R, the package is the toolbox; the function is the tool. We need to load the woodworking toolbox in order to use the hammer. Most of the packages you’ll want to use are not previously installed on R. You’ll need to install them onto your local machine. Once they are installed once, you shouldn’t have to worry about installing them again. Here’s how you install the ggplot2 package. install.packages(&quot;ggplot2&quot;) Paste this code into your console. Then hit enter and watch R run your code to install the packages! If R console returns with a question like, “Would you like to install from source? Yes / No” - answer with Yes. These packages we’re downloading contain pre-written code that other developers have created so we don’t have to recreate the wheel. Source is a location where the package is stored - it’s the initial location it was created, in fact. Think of the package download location as a Car Dealership - all car dealerships sell the same thing, but they all have different cars in different colors from different years. When we select source, we select a car directly from the manufacturer. 3.4 Loading the installed packages into R Here’s the code we use to load a package: library(ggplot2) You may be wondering, why do I need to load in the packages I want to use? R is designed to be fast. If you were to pre-load every single package available in R, you’d be loading thousands and thousands of packages. We can keep R light and fast by only loading the specific “toolboxes” we need. Now that the ggplot2 package is installed, we can use any function that is within that package. If you’re curious about what functions are in a particular package, most packages have thorough documentation and examples online. 3.5 Running Code In R, there are multiple ways to run code. Remember that we write code in an R Script and run that code in the console. We can execute code in the following ways: Click ‘Run’ at the top of the R script. Note that yours may not look the exact same, but just find a Run button to click! This option allows you to run sections of your code, line by line, or the whole script. While the cursor is on a line of code you want to run in the R script, Hit Ctrl + Enter on Windows, Cmd + Enter on Mac. This will run that line of code. Select and highlight the section of code you want to run in the R script, Hit Ctrl + Enter on Windows, Cmd + Enter on Mac.This will run that selected section of code. As you become more advanced, you’ll be able to write a script in RStudio and then run the entire script on your computer without opening it again. We won’t touch this in this workshop, but it’s straight-forward once you get the hang of it. 3.6 Checkpoint - Writing your first R code Let’s write an R script that prints out names, run the code to make sure it works properly, and then save it. # load the base package - remember the # key indicates a comment, R does not run these lines of code! library(base) # let&#39;s create a list with our names names = list(&#39;Peter&#39;, &#39;Sarah&#39;, &#39;Tom&#39;, &#39;Helen&#39;) # now let&#39;s use the print function to print out those names print(names) ## [[1]] ## [1] &quot;Peter&quot; ## ## [[2]] ## [1] &quot;Sarah&quot; ## ## [[3]] ## [1] &quot;Tom&quot; ## ## [[4]] ## [1] &quot;Helen&quot; You can copy and paste this code in your script quadrant and then Run the code as specified above. You can also paste it directly into your console and click enter but note that doing so this way will not save your code. We write scripts, save them, and then run them in the console. Here’s what it looks like when we copy it to the Script quadrant. Now here’s what it looks like after I run the code… 3.7 Explanation - Writing your first R code Line by Line Explanation In this example, we created a variable called names (the object or thing that we create in R that can be called on by it’s variable name - think of this a sa column in Excel). We used the list() function to populate a list of names (we know it’s a function because of the ()). Then we used the print() function to print out the names variable. Once the script has been written, we can navigate to File -&gt; Save As…-&gt; print_names.R . Remember, no spaces in the filename and it must be saved as .R. What’s going on with R/RStudio here? We wrote our script in the Script quadrant of Rstudio. When we were ready to run the script, we ran the code which sent the code down to the console quadrant. The console quadrant is where the R programming language is actually running. Our fancy RStudio application talks to R for us so we don’t have to. Note that our names variable can be found in the Variable Environment quadrant since we ran that object in R. It can now be called on anytime. Now we can see how RStudio is really the middle-man between us and R. Note the term using R may be used as short-hand for saying using RStudio - it’s no longer important to state the difference now that we know what’s really going on. "],
["technical-definitions-rules.html", "4 Technical Definitions &amp; Rules 4.1 Important R Programming Definitions 4.2 Definitions in Action - TV Data Example 4.3 Parantheses (), Brackets [], and Curly brackets", " 4 Technical Definitions &amp; Rules 4.1 Important R Programming Definitions Read through these now to get familiar and refer back to these whenever you need a refresher. You’re not expected to have these memorized or even understood at this moment. These will make more sense as we progress through the course. Coding Name Example Definition syntax R code the nomenclature and structure of a programming language debugging Failed R run debugging involves fixing R code that is written incorrectly and doesn’t run variable names Variables are used to store data, whose value can be changed according to our need. Variables can be declared using &lt;- (tradiational way) or by = (conventional way) package library(ggplot2) A collection of functions prewritten in R function print() A function is a set of statements organized together to perform a specific task. R has a set of preloaded functions that are part of the base package. If a function cannot be found as part of the base package, the function has likely already been built under another package that needs to be loaded in. Functions can be identified due to their enclosing parantheses () arguments read.csv(file = &quot;datasets/tv_shows.csv&quot;, header = FALSE) Components of a function that are separated by commas and declared using the = sign. Arguments in this example are file = and header = index tv_data[3,55] The position of data within a data frame, matrix, list, vector, etc. In R, data is indexed as [row,column] and indexing is done via brackets [] loop for (n in names){print(n)} Repeats a task for a specified number of times. Saves a programmer from repeating codelines with different parameters. logical TRUE, FALSE TRUE and FALSE logical operators are declared using all caps arithmetic operators +,-,*,/,^ Math operators used for addition, subtraction, multiplication, division, exponent, respectively. comparison operators ==, &lt;, &gt;, &lt;=, &gt;=, != Is equal to, less than, greater than, less than or equal to, greater than or equal to, is NOT equal to, respectively and/or operators &amp;, | AND, OR string a_string = &quot;anythign within quotes, single or double&quot; Any value written within a pair of single quote or double quotes in R is treated as a string. numeric 1 Any number - integer, float, etc. vector as.vector(x = c(1,2,3,4)) Vectors are the most basic R data objects and there are six types of atomic vectors. They are logical, integer, double, complex, character and raw. lists list('Peter', 'Sarah', 'Tom', 'Helen') Lists are the R objects which contain elements of different types like − numbers, strings, vectors and another list inside it matrix matrix(c(1:5), nrow = 3, byrow = TRUE) Matrices are the R objects in which the elements are arranged in a two-dimensional rectangular layout. array array(data = c(1,2,3)) Arrays are the R data objects which can store data in more than two dimensions. For example − If we create an array of dimension (1, 2, 3) then it creates 3 rectangular matrices each with 1 rows and 2 columns. Arrays can store only one data type. data frame data.frame(tv_data) R version of Excel Spreadsheet. A data frame is a table or a two-dimensional array-like structure in which each column contains values of one variable and each row contains one set of values from each column. factor factor() Factors are the data objects which are used to categorize the data and store it as levels. They can store both strings and integers. They are useful in the columns which have a limited number of unique values. Like “Male,”Female&quot; and True, False etc. They are useful in data analysis for statistical modeling. help help(read.csv) Default helper function in R. Opens up documentation on a particular function in the lower right quadrant of R. class class(tv_data) Tells us what R is recognizing something as concatenate (c) c(“a”, “b”, “c”) A quick utility for concatenating strings together filepath “/Users/james/Downloads/” The location on your computer where a file is stored. A filepath with a leading slash (akak “/” ) is also referred to as root. Root is the furthest back you can go on your computer. Think of a filepath like this - “/Earth/UnitedStates/Pennsylvania/Lancaster/” Additional examples can be found here 4.2 Definitions in Action - TV Data Example Now that we’re comfortable with R Studio and have some definitions under our belt, let’s dive in a little into some R code and discuss it. Here is a script that loads a dataset about TV shows and examines their IMDb rating. We downloaded this dataset already and can likely be found in your Downloads folder. You’ll need to unzip dataforge-master.zip. The file will be stored in dataforge-master/datasets/tv_shows.csv First, let’s just show the script without running it. # Load in the dataset using the read.csv() function tv_data = read.csv(file = &quot;/Users/james/Downloads/dataforge-master/datasets/tv_shows.csv&quot;, header = FALSE) # have R tell us what class tv_data is class(tv_data) # find the number of rows nrow(tv_data) # print the top 5 rows of the dataset using the head() function head(tv_data) # another way to print out the first 5 rows print(tv_data[1:5, ]) # print out the first 5 rows of the tv_data Title column head(tv_data$Title) # print out the first 5 rows of the tv_data Title Column head(tv_data[&#39;Title&#39;]) # print out the first 7 rows of the tv_data Title Column print(tv_data[&#39;Title&#39;][1:7,]) # sort the tv_data dataframe by the IMDb column from High values to Low values sorted_tv_data = tv_data[order(tv_data$IMDb, decreasing = TRUE), ] # print the top 5 rows of the dataset head(sorted_tv_data) # a column X is bugging me and shouldn&#39;t be there - let&#39;s NULL it out to remove it from our dataframe sorted_tv_data$X = NULL # print the first 10 rows of the sorted_tv_data column print(sorted_tv_data[1:10,]) # Barplot the first 16 rows of tv data ggplot(data = sorted_tv_data[1:16,], mapping = aes(x=Title, y=IMDb)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x=element_text(angle=45, hjust=1)) Now, let’s run the script. Note that this will run line by line, so below each snippet of code, R will execute the code. Remember, the code is executed in the console. R output is designated by the ## library(ggplot2) # Load in the dataset using the read.csv() function tv_data = read.csv(&quot;/Users/james/Downloads/dataforge-master/datasets/tv_shows.csv&quot;) # have R tell us what class tv_data is class(tv_data) ## [1] &quot;data.frame&quot; # print the top 5 rows of the dataset using the head() function head(tv_data) ## X Title Year Age IMDb Rotten.Tomatoes Netflix Hulu Prime.Video ## 1 0 Breaking Bad 2008 18+ 9.5 96% 1 0 0 ## 2 1 Stranger Things 2016 16+ 8.8 93% 1 0 0 ## 3 2 Money Heist 2017 18+ 8.4 91% 1 0 0 ## 4 3 Sherlock 2010 16+ 9.1 78% 1 0 0 ## 5 4 Better Call Saul 2015 18+ 8.7 97% 1 0 0 ## 6 5 The Office 2005 16+ 8.9 81% 1 0 0 ## Disney. type ## 1 0 1 ## 2 0 1 ## 3 0 1 ## 4 0 1 ## 5 0 1 ## 6 0 1 # another way to print out the first 5 rows print(tv_data[1:5, ]) ## X Title Year Age IMDb Rotten.Tomatoes Netflix Hulu Prime.Video ## 1 0 Breaking Bad 2008 18+ 9.5 96% 1 0 0 ## 2 1 Stranger Things 2016 16+ 8.8 93% 1 0 0 ## 3 2 Money Heist 2017 18+ 8.4 91% 1 0 0 ## 4 3 Sherlock 2010 16+ 9.1 78% 1 0 0 ## 5 4 Better Call Saul 2015 18+ 8.7 97% 1 0 0 ## Disney. type ## 1 0 1 ## 2 0 1 ## 3 0 1 ## 4 0 1 ## 5 0 1 # print out the first 5 rows of the tv_data Title column head(tv_data$Title) ## [1] Breaking Bad Stranger Things Money Heist Sherlock ## [5] Better Call Saul The Office ## 5564 Levels: .hack (The Hook Up Plan) #blackAF ... 頭文字D First Stage # print out the first 5 rows of the tv_data Title Column head(tv_data[&#39;Title&#39;]) ## Title ## 1 Breaking Bad ## 2 Stranger Things ## 3 Money Heist ## 4 Sherlock ## 5 Better Call Saul ## 6 The Office # print out the first 7 rows of the tv_data Title Column print(tv_data[&#39;Title&#39;][1:7,]) ## [1] Breaking Bad Stranger Things Money Heist Sherlock ## [5] Better Call Saul The Office Black Mirror ## 5564 Levels: .hack (The Hook Up Plan) #blackAF ... 頭文字D First Stage # sort the tv_data dataframe by the IMDb column from High values to Low values sorted_tv_data = tv_data[order(tv_data$IMDb, decreasing = TRUE), ] # print the top 5 rows of the dataset head(sorted_tv_data) ## X Title Year Age IMDb Rotten.Tomatoes Netflix Hulu ## 3024 3023 Destiny 2014 9.6 0 1 ## 1 0 Breaking Bad 2008 18+ 9.5 96% 1 0 ## 3178 3177 Hungry Henry 2014 9.5 0 1 ## 3748 3747 Malgudi Days 1987 all 9.5 0 0 ## 2366 2365 The Joy of Painting 1983 all 9.4 0 1 ## 3568 3567 Band of Brothers 2001 18+ 9.4 94% 0 0 ## Prime.Video Disney. type ## 3024 0 0 1 ## 1 0 0 1 ## 3178 0 0 1 ## 3748 1 0 1 ## 2366 1 0 1 ## 3568 1 0 1 # a column X is bugging me and shouldn&#39;t be there - let&#39;s NULL it out to remove it from our dataframe sorted_tv_data$X = NULL # print the first 10 rows of the sorted_tv_data column print(sorted_tv_data[1:10,]) ## Title Year Age IMDb Rotten.Tomatoes Netflix Hulu Prime.Video ## 3024 Destiny 2014 9.6 0 1 0 ## 1 Breaking Bad 2008 18+ 9.5 96% 1 0 0 ## 3178 Hungry Henry 2014 9.5 0 1 0 ## 3748 Malgudi Days 1987 all 9.5 0 0 1 ## 2366 The Joy of Painting 1983 all 9.4 0 1 1 ## 3568 Band of Brothers 2001 18+ 9.4 94% 0 0 1 ## 92 Our Planet 2019 7+ 9.3 93% 1 0 0 ## 326 Ramayan 1987 all 9.3 1 0 0 ## 3567 The Wire 2002 18+ 9.3 94% 0 0 1 ## 4129 Green Paradise 2011 all 9.3 0 0 1 ## Disney. type ## 3024 0 1 ## 1 0 1 ## 3178 0 1 ## 3748 0 1 ## 2366 0 1 ## 3568 0 1 ## 92 0 1 ## 326 0 1 ## 3567 0 1 ## 4129 0 1 # Barplot the first 16 rows of tv data ggplot(data = sorted_tv_data[1:16,], mapping = aes(x=Title, y=IMDb)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x=element_text(angle=45, hjust=1)) 4.2.1 Line by Line Discussion Remember that you are not expected to understand this completely at this point - let’s run through this and familiarize ourselves with the code. Code Discussion tv_data = read.csv(file = &quot;/Users/james/Downloads/dataforge-master/datasets/tv_shows.csv&quot;) tv_shows.csv is our filename. &quot;/Users/james/Downloads/dataforge-master/datasets/&quot; is the filepath (the location on our computer where the file is stored). We open the file using the read.csv() function. Within the read.csv() function, we used the file = argument to state which file we wanted to open - note that within functions, arguments can only be specified via the = sign. We name our dataset as tv_data. Notice that we used the = operator to declare our dataset as tv_data, but we also could’ve used the traditional way of &lt;-. Note that if you’re ever confused about where your file is stored, you can enter read.csv(file = &quot;&quot;) into R and with your cursor between the quotations, hit the tab key on your keyboard. This will have R tell you the starting location of where it’s looking for the file. Once this is loaded, run this line of code - now tv_data is an R data.frame class(tv_data) We use the class() function to have R tell us the class of our tv_data nrow(tv_data) we use the nrow() function have R tell us the number of rows in tv_data head(tv_data) The head() function prints out the first 5 rows of an R dataframe. This is the same as viewing the first 5 rows in Microsoft Excel tv_data[1:5,] Here we use indexing (via the [] brackets) to print out the first 5 rows of the tv_data dataframe tv_data[row 1 to row 5, all columns]. In R, the rows and columns are separated by a comma and the colon symbol can be interpreted as to. So, when we have [1:5,] we’re telling R to print row 1 to row 5. By leaving the column part blank (aka part after the comma), we’re telling R to print all columns from the specified rows. head(tv_data$Title) We print out the first 5 rows of the Title column of the tv_data dataframe. We query the Title column using the $ key. If we type tv_data$ and hit the Tab key on our keyboard, R presents us with autocomplete options which are the column names within the tv_data dataset print(tv_data['Title'][1:7,]) We print out the first 7 rows of the Title column using the index method. When querying a column/variable from a dataframe, we can either use the tv_data$Title or we can use the tv_data['Title']. The additional brackets showing [1:7,] print the first 7 rows. sorted_tv_data = tv_data[order(tv_data$IMDb, decreasing = TRUE), ] Here we create a new dataframe called sorted_tv_data where we order the tv_data dataframe by each rows IMDb score. This can be read as from the tv_data dataframe, order the all of the rows based on the tv_data$IMDB column with decreasing order. order() is a function and decreasing = TRUE is an argument of that function. Since the columns are remaining the same, we leave the space after the , blank. head(sorted_tv_data) Print the first 5 lines of our new sorted_tv_data dataframe. sorted_tv_data$X = NULL We notice a column named X and see that it has no meaning since we have a default row number within the R dataframe. We want to delete this column without disturbing the rest of the dataframe. We do so by telling R that the X column shall be converted to NULL, thus removing the column ggplot(data = sorted_tv_data[1:16,], mapping = aes(x=Title, y=IMDb)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x=element_text(angle=45, hjust=1)) Create a ggplot instance from the ggplot2 package. We first create the ggplot instance, declare the data as the first 16 rows of the sorted_tv_data, declare the mapping aesthetics (aes) where we set the x axis of the plot equal to the sorted_tv_data Title, and the y axis equal to the sorted_tv_data IMDB rating. Once ggplot understands the dataset we want to plot and what goes to each axis, we + add a geom_bar to the code, telling ggplot that we want a barplot. We do need to add one argument within the geom_bar function and that is stat = &quot;identity&quot;. stat is the statistical transformation to use on the data for this layer. It’s a fancy way of saying “what should the bars represent?”. In our case, we set stat = &quot;identity&quot; so that the heights of the bars to represent values in the data. ggplot2 is the most popular plotting package in R and creates some beautiful plots. We’ll learn more about ggplot2 in the next section. Need a little more help on a function used above? Use the help feature by running the following in your console! help(ggplot) 4.3 Parantheses (), Brackets [], and Curly brackets A very important aspect to pay attention to are the parantheses, brackets, and curly brackets. Each time we use one of these, the brackets must be opened, then must be closed. What I mean by this is the following: Notice how when we use the head() function, we do so like this head(sorted_tv_data). sorted_tv_data goes inside the enclosed parantheses and thus is an argument of the head() function. Now let’s look at a more complicated example. Similar to the rules of PEMDAS that we learned in algebra, the start and ending of parantheses work in the same way. For example: ggplot(data = sorted_tv_data[1:16,], mapping = aes(x=Title, y=IMDb)) The ggplot function encloses another function by the name of aes (stands for aesthetics). Before we close the ggplot function, we open the aes function. This is because the aes function is declared within the ggplot function. We must close the aes function before we close the ggplot function. In other words, follow along with this example: function(inside_function(inside_inside_function())) The inside_inside_function is here: function(inside_function(inside_inside_function())) The inside_function is here: function(inside_function(inside_inside_function())) The first functions parantheses are enclosing the bolded above. Placing functions within one another is referred to as nested functions. This is handy, but can be difficult to read if too many functions are nested as things are evaluated from the inside out. If you’re ever confused about where a functions parentheses begins and ends, simply place your cursor to the right of a parenthesis. Rule: Always close your parantheses in the right place. The same applies to quotes ( both &quot;&quot; and '' ) You are not expected to fully grasp everything at this point. As we progress through the tutorials, these concepts will make more sense. "],
["avocados-tutorial-part-1.html", "5 Avocados Tutorial - Part 1 5.1 ggplot2 crash course 5.2 Load the avocados Dataset 5.3 Exploring the Dataset 5.4 Expanding the dataset 5.5 Recap 5.6 Avocado Assignment", " 5 Avocados Tutorial - Part 1 For this tutorial, we’ll pretend we work for a supermarket chain interested in avocado pricing. Understanding price changes and the drivers behind those changes can help us forecast future shifts that enable us to stay ahead of the market and create appropriate pricing given the economic environment. Goals of this tutorial Introduce ggplot2 in more detail Install and Load Packages Load and interact with large dataset Practice ggplot2 plots Datasets used avocado.csv 5.1 ggplot2 crash course ggplot2 is the most popular plotting package in R. It’s regarded as one of the best visualization packages of any open-source programming language and has been refactored to work within other languages such as Python. The advantage of ggplot2 is how optimized it is to work with big data. We can create ggplots for thousands of data points in less than a second. Customization options are also endless with ggplot2. ggplot2 can create the following types of plots: 1) Correlation Scatterplot Scatterplot With Encircling Jitter Plot Counts Chart Bubble Plot Animated Bubble Plot Marginal Histogram / Boxplot Correlogram 2) Deviation Diverging Bars Diverging Lollipop Chart Diverging Dot Plot Area Chart 3) Ranking Ordered Bar Chart Lollipop Chart Dot Plot Slope Chart Dumbbell Plot 4) Distribution Histogram Density Plot Box Plot Dot + Box Plot Tufte Boxplot Violin Plot Population Pyramid 5) Composition Waffle Chart Pie Chart Treemap Bar Chart 6) Change Time Series Plots From a Data Frame Format to Monthly X Axis Format to Yearly X Axis From Long Data Format From Wide Data Format Stacked Area Chart Calendar Heat Map Slope Chart Seasonal Plot 7) Groups Dendrogram Clusters 8) Spatial Open Street Map Google Road Map Google Hybrid Map Additional information on these plots can be found at the following links: * http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html * https://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html * https://ggplot2.tidyverse.org/ All ggplot instances follow the same basic format: first calling ggplot and then a plot type. ggplot takes two arguments: the first is a dataset (a data.frame object) and the second is a call to aes(), where you assign variables in the dataset to components of the graph called aesthetics. The specific type of plot you’d like to make with it is the ggplot2 function for the general type of plot you want: for example, a barplot is called geom_bar as we saw in the last example. Let’s quickly explore these: var1 = seq(from=1, to=30, by=1) var2 = rnorm(n=30, mean = 10, sd = 1) df &lt;- data.frame(x = var1, y = var2) head(df) ## x y ## 1 1 9.587496 ## 2 2 10.668359 ## 3 3 9.668145 ## 4 4 9.573960 ## 5 5 12.343406 ## 6 6 9.386927 Now that we have a data frame with variables var1 and var2, we can create a ggplot. Let’s start by creating the background of our ggplot by using the first calling ggplot. library(ggplot2) ggplot(data = df, aes(x = var1, y = y)) The data argument is declared as our df data.frame. Our x axis and y axis are specified by the var1 and var2 variables within the df dataframe. R understands what var1 and var2 are because it assumes the aesthetics are variables within the data dataframe. Now we can plot a ggplot2 instance using this. ggplot(df, aes(x = var1, y = var2)) + geom_point() ggplot is unique in that it’s components are added via the + sign. So we created the ggplot instance with ggplot(df, aes(x = var1, y = var2)) and added the plotting component with + geom_point(). The geom in geom_point stands for geometry. All geometrical plots in ggplot2 begin with geom. ggplot(df, aes(x = var1, y = var2)) + geom_line() Within the plot type we can specify additional arguments to enhance the plot in a way we’d like. ggplot(df, aes(x = var1, y = var2)) + geom_line(color = &quot;darkblue&quot;, linetype = 2, size = 1) We can also add linear regression lines to our plots easily ggplot(df, aes(x = var1, y = var2)) + geom_smooth(method = &quot;lm&quot;) We can have multiple geometry plots on one ggplot instance… ggplot(df, aes(x = var1, y = var2)) + geom_smooth() + geom_point() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Histograms can be done within 1 line. ggplot(df, aes(x = var2)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Density plots are easy too! ggplot(df, aes(x = var2)) + geom_density() Now that we’ve gone through some example plots with ggplot2, let’s use ggplot2 to plot some real data! 5.2 Load the avocados Dataset First we’ll load in the packages and the avocados dataset. # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) library(leaflet) library(lubridate) # now let&#39;s load in our dataset using read.csv avocado_df &lt;- read.csv(&quot;datasets/avocado.csv&quot;) Let’s check out what the avocados dataframe (avocado_df) looks like. # understand what classes R recognizes our data as class(avocado_df) ## [1] &quot;data.frame&quot; # what about the class of the `type` variable within the avocado_df data frame? class(avocado_df$type) ## [1] &quot;factor&quot; 5.3 Exploring the Dataset Is there null data ? What are various columns ? How many years are in this dataset? How many regions and what are they ? Can we create revenue and profit variables? Is there null data? Null data is a feature of most datasets. In R, null data is classified as NA, or Not Available. If there is null data in a dataset, you’ll see an NA in the dataset. For reference, a blank cell in Microsoft Excel would be regarded as NA when read in R. sum(is.na(avocado_df$AveragePrice) == TRUE) ## [1] 0 To find out if there are any null data points we use the is.na() function. This prints out a logical (aka True or False) for each cell. It prints FALSE if there is data and TRUE if the data is NA. In the code above, we tell R to sum() the number of times the is.na reports TRUE for the AveragePrice variable. We see that the return is 0 here, thus telling us that there are no NA data points in this dataset. ** What are the various column names** With most things in R, there are multiple ways to answer the same question. names(avocado_df) ## [1] &quot;X&quot; &quot;Date&quot; &quot;AveragePrice&quot; &quot;Total.Volume&quot; &quot;X4046&quot; ## [6] &quot;X4225&quot; &quot;X4770&quot; &quot;Total.Bags&quot; &quot;Small.Bags&quot; &quot;Large.Bags&quot; ## [11] &quot;XLarge.Bags&quot; &quot;type&quot; &quot;year&quot; &quot;region&quot; colnames(avocado_df) ## [1] &quot;X&quot; &quot;Date&quot; &quot;AveragePrice&quot; &quot;Total.Volume&quot; &quot;X4046&quot; ## [6] &quot;X4225&quot; &quot;X4770&quot; &quot;Total.Bags&quot; &quot;Small.Bags&quot; &quot;Large.Bags&quot; ## [11] &quot;XLarge.Bags&quot; &quot;type&quot; &quot;year&quot; &quot;region&quot; What years are in this dataset? Use the unique function which returns a list of each character string, number, or whatever is in a vector or list. unique(avocado_df$year) ## [1] 2015 2016 2017 2018 What regions are in this dataset? unique(avocado_df$region) ## [1] Albany Atlanta BaltimoreWashington ## [4] Boise Boston BuffaloRochester ## [7] California Charlotte Chicago ## [10] CincinnatiDayton Columbus DallasFtWorth ## [13] Denver Detroit GrandRapids ## [16] GreatLakes HarrisburgScranton HartfordSpringfield ## [19] Houston Indianapolis Jacksonville ## [22] LasVegas LosAngeles Louisville ## [25] MiamiFtLauderdale Midsouth Nashville ## [28] NewOrleansMobile NewYork Northeast ## [31] NorthernNewEngland Orlando Philadelphia ## [34] PhoenixTucson Pittsburgh Plains ## [37] Portland RaleighGreensboro RichmondNorfolk ## [40] Roanoke Sacramento SanDiego ## [43] SanFrancisco Seattle SouthCarolina ## [46] SouthCentral Southeast Spokane ## [49] StLouis Syracuse Tampa ## [52] TotalUS West WestTexNewMexico ## 54 Levels: Albany Atlanta BaltimoreWashington Boise Boston ... WestTexNewMexico How many regions are in this dataset? length(unique(avocado_df$region)) ## [1] 54 ** What types of avocados are in this dataset ** # Remember, we can query information about a variable using avocado_df$type or avocado_df[&#39;type&#39;] unique(avocado_df[&#39;type&#39;]) ## type ## 1 conventional ## 9127 organic There are 2 types of avocados in this dataset - conventional and organic. Let’s use ggplot2 to plot a density plot of the avocados based on the type. ggplot(avocado_df, aes(x=AveragePrice, fill=type)) + geom_density() Let’s expand this a little further and create 2 geom_density plots within 1 window. ggplot(avocado_df, aes(x=AveragePrice, fill=type)) + geom_density() + facet_wrap(~type) In this plot, we declare our ggplot instance, set the type of plot as a geom_density plot, and then use a facet_wrap to create plots from each type of avocado. This allows you to produce plots subset by variables in your data. If we had additional types of avocados, the facet_wrap function would automatically add those to the plot as well! The ~ is necessary in ~type for facet_wrap to be satisfied. Let’s expand on this plot a little further by adding the following adjustments to theme and labs. theme is the ggplot2 theme you use for your ggplot. labs is the label function. With these two functions, we can declare changes to the x and y labels, title, legend position, etc. ggplot(avocado_df, aes(x=AveragePrice, fill=type)) + geom_density() + facet_wrap(~type) + theme(plot.title=element_text(hjust=0.5), legend.position=&quot;bottom&quot;) + labs(title=&quot;Avocado Price by Type&quot;) Great job! Now let’s save this image to share with our team later on! We can do this by navigating to the Plot window (bottom right quadrant), selecting Export and Save As Image. 5.4 Expanding the dataset Before we expand on this dataset, let’s get rid of unnecessary columns that aren’t useful to us. We do this by declaring the variable equal to NULL avocado_df$X = NULL avocado_df$X4046 = NULL avocado_df$X4225 = NULL avocado_df$X4770 = NULL avocado_df$XLarge.Bags = NULL ** Calculating Revenue and Profit ** Revenue = TotalVolume * AveragePrice Profit - Assume that conventional fetches 15% profit of revenue while organic fetchs 45% of revenue Let’s calculate the revenue and add it to our dataframe # we simply multiply the two columns together av_revenue = avocado_df$Total.Volume * avocado_df$AveragePrice # to add our av_revenue vector to the dataframe, add it in like so avocado_df[&#39;revenue&#39;] = av_revenue Now let’s add a blank profit column and populate it based on our conditions above. # add the blank column - remember we can use = or &lt;- for object/variable declaration avocado_df$profit &lt;- NA Now, we need to create 1 profit variable that encompasses 2 conditions. The first is that the conventional avocado has a 15% profit, while the organic avocado has a 45% profit. avocado_df$type[1] ## [1] conventional ## Levels: conventional organic ## use the logical operator to test that avocado_df$type[1] is equal to &#39;conventional&#39; avocado_df$type[1] == &#39;conventional&#39; ## [1] TRUE We see that our test value (row 1 of the avocado_df$type[1]) is conventional and our logical test shows this. Now let’s apply this method above to the profit variable we want to add to the dataset. We’ll do so using the ifelse() function. # let&#39;s use our &quot;is equal to&quot; avocado_df$profit = ifelse(test = avocado_df$type == &#39;conventional&#39;, yes = (avocado_df$revenue * 0.15), no = (avocado_df$revenue * 0.45)) ifelse() takes 3 arguments - test, yes and no. Our test is whether the avocado_df$type is conventional. If it is indeed conventional we multiply our revenue by 0.15 to calculate the profit. Conversely if it is not conventional, then it must be organic and thus we multiply our revenue by 0.45 to calculate the profit. This is the beauty of R in motion. The ifelse() function is automatically rolling through every row and running the same test. Notice how fast this runs. Keep in mind that this dataset is ~18,000 rows long. ** Let’s take a look at our updated dataframe ** It looks great! Let’s save all of our hard work as a new, separate csv file. We do this using the write.csv() function. # x is the dataframe, and the file is the path AND the new filename we want to name our CSV file write.csv(x = avocado_df, file = &quot;/Users/james/Downloads/updated_avocado.csv&quot;) 5.5 Recap ggplot2 is a powerful visualization package ggplot2 takes two objects to create a plot: First, a ggplot instance that creates the x &amp; y axes and second, geom_line or whatever type of plot you want to create. ggplot is unique in that it’s components are added via the + sign Adding and removing columns in our data.frame can be done easily We can save our data.frame to a csv file 5.6 Avocado Assignment Complete the following coding problems and submit the resulting plots and CSV file. HINT: Creating a separate Dataframe of the Albany region is done like so… albany = avocado_df[avocado_df$region == 'Albany',] The profit for California avocados is 5% higher for both conventional and organic avocados. Make an adjustment to the profit variable of the dataframe that reflects the situation where if a rows region is California, the profit is 10% higher for those rows. Save this updated CSV. Create a geom_density() ggplot of the California types of avocados vs. profit. Save this image. Create a new dataframe subselecting the ‘TotalUS’ region. First, plot a geom_point plot of x=Date, y=revenue, and with a facet wrap of the type of avocados. Second, plot a geom_point plot of x=Date, y=profit, and with a facet wrap of the type of avocados. Save these plots. Your final products should look like this… We’ll explore these plots in more detail moving forward - we’ll also clean them up a bit for a nice final product but for now this is great! "],
["avocados-tutorial-part-2.html", "6 Avocados Tutorial - Part 2 6.1 Tidyverse : dplyr crash course 6.2 Avocados Dataframe with dplyr 6.3 Recap 6.4 Avocados 2 Assignment", " 6 Avocados Tutorial - Part 2 We’re going to continue our exploration of the avocados dataset for this tutorial. We’re going to introduce dplyr, an R package with tremendous power that was built with Excel users in mind. Goals of this tutorial * Introduce Tidyverse and dplyr * Practice exploring the avocados dataset using dplyr * Create more advanced ggplot plots * Investigate Avocado price trends Datasets used * avocado.csv 6.1 Tidyverse : dplyr crash course The tidyverse is a collection of R packages for data manipulation, exploration and visualization that share a common design philosophy. The advantages of the tidyverse include consistent functions, workflow coverage, a path to data science education, a parsimonious approach to the development of data science tools, and the possibility of greater productivity. The tidyverse packages can be used in conjunction with any R packages but they are designed to work seamlessly with each other. The basic set of packages are: Figure 6.1: Image courtesy of https://rviews.rstudio.com/2017/06/08/what-is-the-tidyverse/) As we see from the image, we’re already familiar with the visualization package of tidyverse - ggplot2 ! As stated in the introductory material, there are thousands of packages in R, many of which solve the same problem. Tidyverse is just a specific set of packages that are enhanced to work together, so from here on we’re going to stick to this set of R packages for consistency. Tidyverse data science forms what we refer to as tidy datasets, which just refers to specific datasets in tidy format. You can use any R package with tidy datasets and can also use tidyverse packages on a regular data.frame. When you use the set of tidyverse packages together, however, you have some extra functionality which will come in handy. You can read more about tidyverse in this R blog post 6.1.1 Dplyr dplyr is an R package for data manipulation, providing a consistent set of functions that help you solve the most common data manipulation challenges. dplyr is part of the Tidyverse family of packages, thus allowing a user to create tidy datasets. “Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.” (From Wickham, H. (2014): Tidy Data)) select() picks variables based on their names. filter() picks cases based on their values. mutate() adds new variables that are functions of existing variables summarise() reduces multiple values down to a single summary. arrange() changes the ordering of the rows. These all combine naturally with group_by() which allows you to perform any operation by group. 6.1.2 Exploring Dplyr Let’s begin by loading our packages and opening the avocados dataset back up. # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) library(leaflet) library(lubridate) library(cowplot) # now let&#39;s load in our dataset using read.csv avocado_df &lt;- read.csv(&quot;datasets/avocado.csv&quot;) Now, let’s use dplyr with this dataset. First, let’s select a subset of this dataset using the select() function # subselect the Average Price, Total Volume, and type from our original dataset select_df &lt;- select(.data = avocado_df, AveragePrice, Total.Volume, type) A key thing to notice here is the arguments after the .data argument. If we use the help() function to learn more about select(), we see that the arguments are .data. and .... The ... is another way to describe ambiguous arguments - meaning you can add as many or as few as you want. In this case, we want the variable names we want to select here. Note that even though it’s good practice to always use the convention of argument = my_specific_argument_condition, you don’t have to add the argument = part so long as the arguments are written in the same order the function expects. For example, in the code above, we don’t need to write select(.data = avocado_df, AveragePrice, Total.Volume, type), we can simply write select(avocado_df, AveragePrice, Total.Volume, type). This is true for ALL functions, but you’ll need to keep the order of your arguments straight. Now let’s filter the original avocado_df to extract cases where avocados are organic # filter the dataset when the type is organic filter_df &lt;- filter(.data = avocado_df, type==&#39;organic&#39;) Now let’s mutate the dataset and add our revenue and profit columns. # filter the dataset when the type is organic mutate_df = mutate(avocado_df, revenue = AveragePrice *Total.Volume) 6.1.3 Nested Functions Let’s say we want to create a sub-selected dataset of AveragePrice, Total.Volume, and type where the region is Northeast. nested_df = select(.data = filter(.data = avocado_df, region==&#39;Northeast&#39;), AveragePrice, Total.Volume, type) Notice how our .data is the result of the filter() function where we select only the Northeast region. Here’s what the nested_df looks like now. 6.1.4 Pipes %&gt;% The last option for handling data with dplyr, pipes, are a fairly recent addition to R. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. You’ll see more advanced code make use of this. We’ll show a quick example here so you can see how it works, but we won’t use it for the rest of the tutorial after this. Let’s do the exact same thing above only this time let’s use pipes. pipe_df &lt;- avocado_df %&gt;% filter(region==&#39;Northeast&#39;) %&gt;% select(AveragePrice, Total.Volume, type) Above code reads like so to create the pipe_df dataframe. Begin with avocado_df and send that to the filter() function where we grab the Northeast region from the avocado_df dataset, then immediately send the result of the filter to the select function where we sub-select the AveragePrice, Total.Volume, type variables. As we’ll see, the output is the same - it’s just another way of coding! 6.2 Avocados Dataframe with dplyr In this tutorial we’re going to accomplish the following: Plot Price Trends over time for both types of avocados 6.2.1 Price Trends First, let’s check out our date column. # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(tibbletime) # now let&#39;s load in our dataset using read.csv avocado_df &lt;- read.csv(&quot;datasets/avocado.csv&quot;) class(avocado_df$Date) ## [1] &quot;factor&quot; We need to change the class of the avocado_df$Date column. We can do this using as.Date function that can reclassify a variable as a date class in R. We know that the date is stored as Year-Month-Day, so we relay this to R which uses the following format for classifying datestrings &quot;%Y-%m-%d&quot; . %Y is a 4 digit year, %m is a 2 digit month, and %d is a 2 digit day. More can be read on this here. # Change the date column from factor to date avocado_df$Date &lt;- as.Date(avocado_df$Date, &quot;%Y-%m-%d&quot;) class(avocado_df$Date) ## [1] &quot;Date&quot; Now let’s sort the dates via the order function so we can analyze the price trends over time. # Sort the dates avocado_df &lt;- avocado_df[order(avocado_df$Date),] head(avocado_df$Date) ## [1] &quot;2015-01-04&quot; &quot;2015-01-04&quot; &quot;2015-01-04&quot; &quot;2015-01-04&quot; &quot;2015-01-04&quot; ## [6] &quot;2015-01-04&quot; Now let’s select the columns we want using dplyr and plot them using ggplot price_trend &lt;- select(.data = avocado_df, Date, AveragePrice, type) ggplot(data = price_trend, aes(x = Date, y = AveragePrice, col=type)) + geom_line() + facet_wrap(~type) + theme(legend.position=&quot;bottom&quot;) Notice that we had the following arguments in the aes parameter - x, y, col. Our x axis is the date, y axis is the AveragePrice, and we color the data based on the type of avocado. Can we spice this plot up a bit by customizing the colors? Sure! Altering the colors of the plots using scale_color_manual # Create a Facet Wrap for each product ggplot(data = price_trend, aes(x = Date, y = AveragePrice, col=type)) + geom_line() + facet_wrap(~ type) + theme_minimal() + theme(legend.position=&quot;bottom&quot;) + scale_color_manual(values=c(&quot;blue&quot;, &quot;green&quot;)) # Create a Facet Wrap for each product ggplot(data = price_trend, aes(x = Date, y = AveragePrice, col=type)) + geom_line() + facet_wrap(~ type) + theme_minimal() + theme(legend.position=&quot;bottom&quot;) + scale_color_manual(values=c(&quot;dodgerblue4&quot;, &quot;darkgreen&quot;)) We used the function scale_color_manual because we defined the coloring via the col argument in the aes function. Had we chosen another function that requires a fill instead of a col, we would have had to use scale_fill_manual. Notice that the argument for the scale_color_manual is values=, which takes a list that must be the same length as the input parameters. R has a wide range of colors to choose from - a list can be found here. we see that the average price of organic avocados is higher than conventional avocados. 6.2.2 Price and Total Volume Supply and demand is key component of pricing. Let’s examine the relationship between the price and total volume. We begin by creating separate dataframes for organic and conventional. # Filter by type - our input data for selected variabls is teh filtered organic/conventional data organic &lt;- select(.data = filter(.data = avocado_df,type == &quot;organic&quot;), Date, AveragePrice, type, Total.Volume) conventional &lt;- select(.data = filter(.data = avocado_df,type == &quot;conventional&quot;), Date, AveragePrice, type, Total.Volume) We’ve created our two new datasets. Let’s say we want to average the data by month to make it easier to work with and analyze. This is easy once we convert our data.frame to a tibbletime tbl_df. tibbletime is a separate tibble package that obeys the nomenclature associated with the greater R Tidyverse. tibbletime is an advanced R package that is great when working with dataframes. It also allows us to convert our standard R data.frame to a tibbletime data.frame. This allows us to do fancy things with the dataframe like average the data by each month of the datetime. # organize the organic dataframe as a tbl_time object where the index is the Date organic &lt;- as_tbl_time(organic, index=Date) class(organic) ## [1] &quot;tbl_time&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; We can use the as_period function to average this data into a monthly dataset. organic &lt;- as_period(organic, &#39;1 month&#39;) Let’s do the same for conventional avocados # Conventional Avocadoes conventional &lt;- as_tbl_time(conventional, index=Date) conventional &lt;- as_period(conventional, &#39;1 month&#39;) Now let’s plot up the the price trends with the volume trends of both types of avocados. We’ll be creating a total of 4 plots and we’ll want them in the same window. In order to achieve this, we will use a package called cowplot which has a function called plot_grid. plot_grid allows us to plot any number of ggplot instances in the same window. # Let&#39;s create a conventional average price chart conventional_price &lt;- ggplot(data = conventional, aes(x=Date, y=AveragePrice)) + geom_line(color=&quot;dodgerblue2&quot;) + labs(title=&quot;Conventional Avocados&quot;) + geom_hline(yintercept=max(conventional$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept=min(conventional$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;blue&quot;) # Let&#39;s create a conventional volume chart conventional_volume &lt;- ggplot(data = conventional, aes(x=Date, y=Total.Volume)) + geom_bar(stat=&#39;identity&#39;, fill=&quot;dodgerblue2&quot;, color=&quot;black&quot;) + geom_smooth(method=&quot;loess&quot;, color=&quot;red&quot;) # Let&#39;s create an organic average price chart organic_price = ggplot(data = organic, aes(x=Date, y=AveragePrice)) + geom_line(color=&quot;darkgreen&quot;) labs(title=&quot;Organic Avocados&quot;) + geom_hline(yintercept=max(organic$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept=min(organic$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;blue&quot;) ## NULL # Let&#39;s create a organic volume chart organic_volume &lt;- ggplot(data = organic, aes(x=Date, y=Total.Volume)) + geom_bar(stat=&#39;identity&#39;, fill=&quot;darkgreen&quot;,color=&quot;black&quot;) + geom_smooth(method=&quot;loess&quot;, color=&quot;yellow&quot;) #now use cowplot plot_grid to plot all 4 plots in the same window plot_grid(conventional_price, organic_price,conventional_volume, organic_volume, nrow=2, ncol=2) Notice that we created 4 separate ggplots and saved them as objects. Once we had all of the objects created, we placed them in plot_grid as the plots we wanted to add to the plot_grid window. Then we specified the number of rows and columns we wanted the grid to have via nrow and ncol, respectively. Summary: 2015 prices were in the $1.00 range for conventional avocados. In 2016 and 2017, the density of the prices were a little bit higher. It looks that most price peaks occur for both conventional and organic avocados between the months of September and October. I wonder why this is? Could it have to do with fall sport viewing which is often accompanied by guacamole? Major price drop at the end of each year. Why is demand dropping so much? 6.2.3 Yearly and Monthly Patterns We have 4 years of data in this dataset, so we have 4 values for each month when it comes to Average Price. Let’s reorganize our data to include a month variable and then average the 4 values for each month together to create a monthly price point average. # create a separate dataframe by first copying the original avocado_df seasonal_df &lt;- avocado_df # create 3 new variables, just expanding on the date using the format function # let&#39;s test out the format function to see what it does avocado_df$Date[1] ## [1] &quot;2015-01-04&quot; format(as.Date(avocado_df$Date[1]), &quot;%Y-%m&quot;) ## [1] &quot;2015-01&quot; # create the variables - notice the structure of the format seasonal_df$month_year &lt;- format(as.Date(avocado_df$Date), &quot;%Y-%m&quot;) seasonal_df$month &lt;- format(as.Date(avocado_df$Date), &quot;%m&quot;) seasonal_df$year &lt;- format(as.Date(avocado_df$Date), &quot;%Y&quot;) # print out the first 10 values seasonal_df$month[1:10] ## [1] &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; Let’s take this one step further and let’s convert our month variable to an Abbreviated Month (aka month “01”&quot; is Jan). We can do this by using the month.abb function (which requires the input to be a numeric, so we convert the seasonal_df$month to numeric within the funciton) seasonal_df$monthchr &lt;- month.abb[as.numeric(seasonal_df$month)] seasonal_df$monthchr[1:10] ## [1] &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; class(seasonal_df$monthchr) ## [1] &quot;character&quot; This is a character, so let’s change this to a factor where the levels available are R’s abbreviated months - aka month.abb seasonal_df$monthabb = factor(seasonal_df$monthchr, levels = month.abb) seasonal_df$monthabb[1:10] ## [1] Jan Jan Jan Jan Jan Jan Jan Jan Jan Jan ## Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Our dataset is now organized - let’s plot it up to learn more about the avocados! First let’s plot a density plot of the distribution of prices by year. ** Distribution of Average Prices by year for both avocado types ** ggplot(seasonal_df, aes(x = AveragePrice, fill = as.factor(year))) + geom_density(alpha = .5) + facet_wrap(~year) + labs(title=&quot;Distribution of Prices by year&quot;, x = &#39;Average Price&#39;, y = &#39;Density&#39;) + scale_fill_manual(values=c(&quot;blue&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;red&quot;)) Notice that we used the scale_fill_manual argument here because the geom_density argument requires a fill value in the ggplot components aes function. ** Distribution of Average Prices by month for the Conventional Avocado ** Let’s select the conventional avocados using select and filter from dplyr. conventional = select(.data = filter(.data = seasonal_df,type == &#39;conventional&#39;), monthabb, AveragePrice, type) Now, let’s group this dataframe by the monthabb variable month_df = group_by(.data = conventional, monthabb) Now, we can summzarize this data by taking the mean() of the AveragePrice variable and creating a new variable named avg month_df = summarize(.data = month_df, avg=mean(AveragePrice)) Plot the price distrubion by month! ggplot(data = month_df, aes(x=monthabb, y=avg)) + geom_point(color=&quot;red&quot;, aes(size=avg)) + geom_line(group=1, color=&quot;blue&quot;) + labs(title=&quot;Conventional Avocados&quot;, x=&quot;Month&quot;, y=&quot;Average Price&quot;) Summary: - October is the best month for Conventional Avocados for the entire dataset with average prices above $1.30 - February is the worst month for Conventional Avocados with average prices barely above $1.00 6.3 Recap Tidyverse is a set of R packages designed with consistent framework and usability - dplyr and tibbletime are very useful when dealing with spreadsheet data Subselecting, grouping, averaging can all be accomplished with dplyr and tibbletime plot_grid from the cowplot package is useful for plotting multiple ggplot2 plots in the same window ggplot2 plots are extremely customizable - we used scale_color_manual as one example of how customizable they are here. 6.4 Avocados 2 Assignment Perform the same analysis onthe price distribution by month that we did for Conventional Avocados only this time explor the Organic type of avocados. Combine both plots to be part of the same window. Use custom colors selected from the R color guide. Create proper labels with ggplot2s lab() function. Submit final plot. Your final plot should look something like this… "],
["us-work-visas-part-1.html", "7 US Work Visas - Part 1 7.1 The For Loop - Quick Introduction 7.2 paste() and paste0() - Quick Introduction 7.3 Exploring the Data 7.4 Recap 7.5 Visa 1 Assignment", " 7 US Work Visas - Part 1 In this tutorial, we’ll be exploring the H1-B Visa. The H-1B is a visa in the United States which allows U.S. employers to employ foreign workers in specialty occupations. We’ll examine what kind of foreign workers are most often employed. Goals of this tutorial Introduce the for loop and paste0 Use R to load in big data Practice using dplyr and tibble on the visa dataset Investigate H1-B visa trends Datasets used h1bvisa_part1.csv h1bvisa_part2.csv h1bvisa_part3.csv h1bvisa_part4.csv h1bvisa_part5.csv h1bvisa_part6.csv h1bvisa_part7.csv 7.1 The For Loop - Quick Introduction For loops &amp; conditional statements are a key skill in programming. They allow you to process through large datasets or multiple datasets thus minimizing the amount of manual work you need to do. The basic for loop looks like this… # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result for (i in numbersList){ temNumber = i * 8 print(temNumber) } ## [1] 8 ## [1] 16 ## [1] 24 ## [1] 32 ## [1] 40 ## [1] 48 ## [1] 56 ## [1] 64 ## [1] 72 ## [1] 80 Notice the general structure of R for loops. ‘for’ signals to R you’re beginning a for loop, which requires the general structure to look like: for (numbers/values to loop through){ condition for the looping using the numbers/values above } Yes, you must have these parentheses and curly brackets present and surrounding the appropriate code. If you forget a parentheses or curly bracket you’ll have errors pop up…this happens to me all the time still. While these must be present, R doesn’t care where they are in your code (****which is very unique amongst programming languages). For example, notice how this ugly code is different but still runs… # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result for ( i in numbersList ){ temNumber = i * 8 print(temNumber) } ## [1] 8 ## [1] 16 ## [1] 24 ## [1] 32 ## [1] 40 ## [1] 48 ## [1] 56 ## [1] 64 ## [1] 72 ## [1] 80 The general structure is still: for(condition){do something}. If statements are set up the same way # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result for (i in numbersList){ if (i==4){ temNumber = i * 8 print(temNumber) } } ## [1] 32 This is referred to as a ‘nested loop’, because there is a conditional statement within another one. Key takeaway here: in programming languages, ‘=’ is an assignment (i.e. x = 4), whereas ‘==’ is an equality test (i == 4). To put this loop in layman’s terms: for i in numbersList, if i is equal to 4, multiply i by 8 and then print temNumber. We can also have nested for loops. # Generate sequence of numbers from 1 to 3 this time using the seq() function (seq for sequence) numbersList = seq(from=1,to=3,by=1) lettersList = list(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) for (num in numbersList){ for (let in lettersList){ print(c(num,let)) } } ## [1] &quot;1&quot; &quot;A&quot; ## [1] &quot;1&quot; &quot;B&quot; ## [1] &quot;1&quot; &quot;C&quot; ## [1] &quot;2&quot; &quot;A&quot; ## [1] &quot;2&quot; &quot;B&quot; ## [1] &quot;2&quot; &quot;C&quot; ## [1] &quot;3&quot; &quot;A&quot; ## [1] &quot;3&quot; &quot;B&quot; ## [1] &quot;3&quot; &quot;C&quot; You can name the object within the list whatever you want (i, j, num, let, etc.). Reminder, c() is the concatenate functin that combines values into a vector or list. The order doesn’t matter in this for loop… # Generate sequence of numbers from 1 to 3 this time using the seq() function (seq for sequence) numbersList = seq(from=1,to=3,by=1) lettersList = list(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) for (let in lettersList){ for (num in numbersList){ print(c(num,let)) } } ## [1] &quot;1&quot; &quot;A&quot; ## [1] &quot;2&quot; &quot;A&quot; ## [1] &quot;3&quot; &quot;A&quot; ## [1] &quot;1&quot; &quot;B&quot; ## [1] &quot;2&quot; &quot;B&quot; ## [1] &quot;3&quot; &quot;B&quot; ## [1] &quot;1&quot; &quot;C&quot; ## [1] &quot;2&quot; &quot;C&quot; ## [1] &quot;3&quot; &quot;C&quot; But it does in this one… # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result if (i==4){ for (i in numbersList){ temNumber = i * 8 print(temNumber) } } Here’s one more example for multi conditional statement with an else… # Generate sequence of numbers from 1 to 3 this time using the seq() function (seq for sequence) numbersList = seq(from=1,to=3,by=1) lettersList = list(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) for (num in numbersList){ for (let in lettersList){ if (num == 3 &amp;&amp; let == &quot;B&quot;){ print(c(num,let)) } else{ print(&quot;Not what we want&quot;) } } } ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;3&quot; &quot;B&quot; ## [1] &quot;Not what we want&quot; &amp;&amp; means “and” … || means “or”…these are useful in multi conditional statements. The ‘else’ statement is an appendage of the ‘if’ statement. It basically means if num == 3 and let == B is false, print “not what we want”. Notice that the ‘else’ statement is outside of the ‘if’ statement but immediately after it. 7.2 paste() and paste0() - Quick Introduction paste() paste0() are some of the most commonly used functions in R. These allow you concatenate a series of strings together into 1. This is very handy when it comes ot writing filepaths to read/write data files. # Paste Example 1 - default sep (aka separation) is space paste(&quot;file&quot;, &quot;number&quot;, &quot;32&quot;) ## [1] &quot;file number 32&quot; # Paste Example 2 - set sep to &quot;_&quot; paste(&quot;file&quot;, &quot;number&quot;, &quot;32&quot;, sep = &quot;_&quot;) ## [1] &quot;file_number_32&quot; # Paste0 Example 1 - 0 for 0 separating characters paste0(&quot;file&quot;, &quot;number&quot;, &quot;32&quot;) ## [1] &quot;filenumber32&quot; # Notice that paste() is limiting because the separating character is not always present between # each string you&#39;re concatenating # Let&#39;s use paste0 here fileList &lt;- c(&#39;filename1&#39;, &#39;filename2&#39;, &#39;filename3&#39;, &#39;filename4&#39;) dateFolder &lt;- c(&#39;0813&#39;, &#39;0814&#39;, &#39;0815&#39;, &#39;0816&#39;) homeDir &lt;- &quot;~/Documents/&quot; pathList &lt;- list() for (i in 1:length(fileList)){ print(i) tempString &lt;- paste0(homeDir, dateFolder[i], &#39;/&#39;, fileList[i]) pathList[i] &lt;- tempString } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 pathList ## [[1]] ## [1] &quot;~/Documents/0813/filename1&quot; ## ## [[2]] ## [1] &quot;~/Documents/0814/filename2&quot; ## ## [[3]] ## [1] &quot;~/Documents/0815/filename3&quot; ## ## [[4]] ## [1] &quot;~/Documents/0816/filename4&quot; pathList[[1]] ## [1] &quot;~/Documents/0813/filename1&quot; 7.3 Exploring the Data 7.3.1 Reading in multiple datasets and combining them # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) library(leaflet) library(lubridate) library(cowplot) For this tutorial, we have 7 separate CSV files. Let’s show a few different ways to load all 7 and merge them together into a single data.frame instance. The first way we’ll show loading in multiple datasets is the for loop! # define our path path = &quot;datasets/visa_data/&quot; # first, create a sequence of numbers 1:7 nseq = seq(1,7) csv_list = list() # create a list of all the filenames for (n in nseq){ csv_list[n] = paste0(&#39;h1bvisa_part&#39;, n, &#39;.csv&#39;) } # now using that list above, let&#39;s read in all files and then append them to the original dataframe for (c in 1:length(csv_list)){ if (c == 1){ visa_df = read.csv(paste0(path, csv_list[c])) } else { nextPart = read.csv(paste0(path, csv_list[c])) visa_df = rbind(visa_df, nextPart) } } # check out the class class(visa_df) ## [1] &quot;data.frame&quot; # check out the dimensions dim(visa_df) ## [1] 647809 12 # check out the dimensions if our `nextPart` that&#39;s being overwritten dim(nextPart) ## [1] 47804 12 Let’s break down this code. First we declare our list of CSV names and the Path that they’re located at. Then, we begin the for loop. We state that for c in 1 to the length of the csv_list (i.e. - 1 to 3), do what’s in the loop. Inside the loop, our first clause states that if c==1 we want to create a data.frame called visa_df. We use our read.csv() function and direct that function to the path and filename of our csv. If it’s the 2nd or 3rd iteration of the loop, the visa_df is already created and thus we want to append our additional data to this data.frame. We do this by loading in the CSV files to our temporary nextPart variable. Once nextPart is loaded, we then use the rbind() function which stands for row bind. We bind together the two dataframes (visa_df and nextPart) by their rows. In other words, we just add in the additional data as additional rows since the datasets share the same column names. The end product is our single dataframe that we created from 3 separate csv files. ## Warning in instance$preRenderHook(instance): It seems your data is too big ## for client-side DataTables. You may consider server-side processing: https:// ## rstudio.github.io/DT/server.html As with many things in R, there are multiple ways to achieve the same goal. Here’s a more advanced (yet simpler) way to read in and merge these files. library(dplyr) library(readr) # set the path csv_path = &quot;datasets/visa_data/&quot; # list all files within that path csv_list = list.files(path=csv_path, full.names = TRUE) csv_list ## [1] &quot;datasets/visa_data//h1bvisa_part1.csv&quot; ## [2] &quot;datasets/visa_data//h1bvisa_part2.csv&quot; ## [3] &quot;datasets/visa_data//h1bvisa_part3.csv&quot; ## [4] &quot;datasets/visa_data//h1bvisa_part4.csv&quot; ## [5] &quot;datasets/visa_data//h1bvisa_part5.csv&quot; ## [6] &quot;datasets/visa_data//h1bvisa_part6.csv&quot; ## [7] &quot;datasets/visa_data//h1bvisa_part7.csv&quot; # Read all csv files in the folder and create a list of dataframes ldf &lt;- lapply(csv_list , read.csv) # Combine each dataframe in the list into a single dataframe visa_df &lt;- do.call(&quot;rbind&quot;, ldf) In this more advanced example, we load in the packages that contain the following functions (this is already done above, but I’m doing it again to show you where these functions come from). After setting the csv_path, we then use the function list.files() which lists all files within a give path. In our case, all of our Visa CSV data is located within /datasets/visa_data. Then we use the lapply function which is a function useful for performing operations on list objects and returns a list object of same length of original set. We give lapply a list (csv_list) and a function (read.csv) to do on that list. This creates a larger list of the output of read_csv from our csv_list. Finally, we create our visa_df via the do.call function (which behaves very similar to lapply). The do.call function is given a function (rbind) and then a list to perform that function on (ldf). lapply and do.call are similar but here’s the difference: lapply() applies a given function for each element in a list,so there will be several function calls. do.call() applies a given function to the list as a whole,so there is only one function call. Once again, here’s our visa_df ## Warning in instance$preRenderHook(instance): It seems your data is too big ## for client-side DataTables. You may consider server-side processing: https:// ## rstudio.github.io/DT/server.html Now that we have our dataset, let’s explore it! 7.3.2 Manipulating our Data Frame X1,X2,X - not named column, it is the id of the row; CASE_STATUS - status of the application; EMPLOYER_NAME - the name of the employer as registered in the H-1B Visa application; SOC_NAME - the occupation code for the employment; JOB_TITLE - the job title for the employment; FULL_TIME_POSITION - whether the application is for a full-time position of for a part-time position; PREVAILING_WAGE - the most frequent wage for the corresponding role as filled in the Visa application; YEAR - the application year; WORKSITE - the address of the employer worksite; lon - longitude of the employer worksite; lat - latitude of the employer worksite; First, let’s get rid of columns we don’t need like X.2, X.1, and X. visa_df$X.2 = NULL visa_df$X.1 = NULL visa_df$X = NULL Next, we notice that the WORKSITE variable contains a City, State type string. Let’s break this out and create a new column with just states. library(stringr) # str_split or string split is a great function to use. It breaks up a string based on a character. In this case we want to split our string into a list of cities and states which are split by a comma worksites = str_split(visa_df$WORKSITE, &quot;,&quot;, simplify = TRUE) head(worksites) ## [,1] [,2] ## [1,] &quot;ANN ARBOR&quot; &quot; MICHIGAN&quot; ## [2,] &quot;PLANO&quot; &quot; TEXAS&quot; ## [3,] &quot;JERSEY CITY&quot; &quot; NEW JERSEY&quot; ## [4,] &quot;DENVER&quot; &quot; COLORADO&quot; ## [5,] &quot;ST. LOUIS&quot; &quot; MISSOURI&quot; ## [6,] &quot;MIAMI&quot; &quot; FLORIDA&quot; # grab the second column which is just the states states = worksites[,2] head(states) ## [1] &quot; MICHIGAN&quot; &quot; TEXAS&quot; &quot; NEW JERSEY&quot; &quot; COLORADO&quot; &quot; MISSOURI&quot; ## [6] &quot; FLORIDA&quot; # Now we can use the trimws() function to trim the whitespace and get rid of the leading spaces states = trimws(states) head(states) ## [1] &quot;MICHIGAN&quot; &quot;TEXAS&quot; &quot;NEW JERSEY&quot; &quot;COLORADO&quot; &quot;MISSOURI&quot; ## [6] &quot;FLORIDA&quot; # now add it to the dataframe visa_df$states &lt;- states Next we notice that our Latitudes and Longitude columns are very specific, let’s round these to make them easier on the eye. visa_df$lat = round(visa_df$lat,3) visa_df$lon = round(visa_df$lon,3) 7.3.3 Case Status Investigation One of the key metrics of this dataset is the Case Status. Let’s filter out the NA values in the dataset and plot this up. # use the filter function from dplyr to filter the visa_df for all cases where CASE_STATUS is NOT NA (!is.na) case_df = filter(.data = visa_df, !is.na(CASE_STATUS)) head(case_df) ## CASE_STATUS ## 1 CERTIFIED-WITHDRAWN ## 2 CERTIFIED-WITHDRAWN ## 3 CERTIFIED-WITHDRAWN ## 4 CERTIFIED-WITHDRAWN ## 5 WITHDRAWN ## 6 CERTIFIED-WITHDRAWN ## EMPLOYER_NAME ## 1 UNIVERSITY OF MICHIGAN ## 2 GOODMAN NETWORKS, INC. ## 3 PORTS AMERICA GROUP, INC. ## 4 GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY OF TOMKINS PLC ## 5 PEABODY INVESTMENTS CORP. ## 6 BURGER KING CORPORATION ## SOC_NAME ## 1 BIOCHEMISTS AND BIOPHYSICISTS ## 2 CHIEF EXECUTIVES ## 3 CHIEF EXECUTIVES ## 4 CHIEF EXECUTIVES ## 5 CHIEF EXECUTIVES ## 6 CHIEF EXECUTIVES ## JOB_TITLE ## 1 POSTDOCTORAL RESEARCH FELLOW ## 2 CHIEF OPERATING OFFICER ## 3 CHIEF PROCESS OFFICER ## 4 REGIONAL PRESIDEN, AMERICAS ## 5 PRESIDENT MONGOLIA AND INDIA ## 6 EXECUTIVE V P, GLOBAL DEVELOPMENT AND PRESIDENT, LATIN AMERI ## FULL_TIME_POSITION PREVAILING_WAGE YEAR WORKSITE lon ## 1 N 36067.0 2016 ANN ARBOR, MICHIGAN -83.743 ## 2 Y 242674.0 2016 PLANO, TEXAS -96.699 ## 3 Y 193066.0 2016 JERSEY CITY, NEW JERSEY -74.078 ## 4 Y 220314.0 2016 DENVER, COLORADO -104.990 ## 5 Y 157518.4 2016 ST. LOUIS, MISSOURI -90.199 ## 6 Y 225000.0 2016 MIAMI, FLORIDA -80.192 ## lat states ## 1 42.281 MICHIGAN ## 2 33.020 TEXAS ## 3 40.728 NEW JERSEY ## 4 39.739 COLORADO ## 5 38.627 MISSOURI ## 6 25.762 FLORIDA # Now let&#39;s group the data by Case_status case_df = group_by(.data = case_df, CASE_STATUS) head(case_df) ## # A tibble: 6 x 11 ## # Groups: CASE_STATUS [2] ## CASE_STATUS ## &lt;fct&gt; ## 1 CERTIFIED-WITHDRAWN ## 2 CERTIFIED-WITHDRAWN ## 3 CERTIFIED-WITHDRAWN ## 4 CERTIFIED-WITHDRAWN ## 5 WITHDRAWN ## 6 CERTIFIED-WITHDRAWN ## EMPLOYER_NAME ## &lt;fct&gt; ## 1 UNIVERSITY OF MICHIGAN ## 2 GOODMAN NETWORKS, INC. ## 3 PORTS AMERICA GROUP, INC. ## 4 GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY OF TOMKINS PLC ## 5 PEABODY INVESTMENTS CORP. ## 6 BURGER KING CORPORATION ## SOC_NAME ## &lt;fct&gt; ## 1 BIOCHEMISTS AND BIOPHYSICISTS ## 2 CHIEF EXECUTIVES ## 3 CHIEF EXECUTIVES ## 4 CHIEF EXECUTIVES ## 5 CHIEF EXECUTIVES ## 6 CHIEF EXECUTIVES ## JOB_TITLE ## &lt;fct&gt; ## 1 POSTDOCTORAL RESEARCH FELLOW ## 2 CHIEF OPERATING OFFICER ## 3 CHIEF PROCESS OFFICER ## 4 REGIONAL PRESIDEN, AMERICAS ## 5 PRESIDENT MONGOLIA AND INDIA ## 6 EXECUTIVE V P, GLOBAL DEVELOPMENT AND PRESIDENT, LATIN AMERI ## FULL_TIME_POSITION PREVAILING_WAGE YEAR WORKSITE lon lat ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 N 36067 2016 ANN ARBOR, MICHIGAN -83.7 42.3 ## 2 Y 242674 2016 PLANO, TEXAS -96.7 33.0 ## 3 Y 193066 2016 JERSEY CITY, NEW JERSEY -74.1 40.7 ## 4 Y 220314 2016 DENVER, COLORADO -105. 39.7 ## 5 Y 157518. 2016 ST. LOUIS, MISSOURI -90.2 38.6 ## 6 Y 225000 2016 MIAMI, FLORIDA -80.2 25.8 ## states ## &lt;chr&gt; ## 1 MICHIGAN ## 2 TEXAS ## 3 NEW JERSEY ## 4 COLORADO ## 5 MISSOURI ## 6 FLORIDA # Now let&#39;s summarize the data based on total number of cases which would be the length of any variable within each sub-group. Here we choose the `lat` variable but it could be any variable here case_df = summarise(.data = case_df, total_cases = length(lat)) head(case_df) ## # A tibble: 4 x 2 ## CASE_STATUS total_cases ## &lt;fct&gt; &lt;int&gt; ## 1 CERTIFIED 569650 ## 2 CERTIFIED-WITHDRAWN 47094 ## 3 DENIED 9175 ## 4 WITHDRAWN 21890 # plot it up! ggplot(data = case_df, aes(x = reorder(CASE_STATUS,total_cases), y = total_cases/1000)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;coral&quot;, colour=&quot;dodgerblue4&quot;) + labs(title=&quot;H1-B Visa Applications&quot;, x =&quot;Case Status&quot;, y = &quot;Number of applications (thousands)&quot;) Something to notice with this ggplot instance is the aes edits for x and y arguments. Notice that we reorder the CASE_STATUS based on the total_cases metric. Also see that we divide teh total_cases by 1000 in order to make the graph more general. Over 100,000 cases are Certified. Less than 5,000 cases are denied. 7.3.4 Job Titles What’s the most common type of job for these visa requests? To find out, we’ll have to look at the JOB_TITLE variable. Let’s organize the data based on this variable # group the data based on the JOB_TITLE variable job_df = group_by(.data = visa_df, JOB_TITLE) ## Warning: Factor `JOB_TITLE` contains implicit NA, consider using ## `forcats::fct_explicit_na` # summarize the data based on the total number of each JOB TITLE, here we aggregate the total number of latitude values for each JOB TITLE job_df = summarise(.data = job_df, total_records = length(lat)) # trim our dataset down so that we only keep the top 50 JOB_TITLE values job_df = top_n(x= job_df, n=50) ## Selecting by total_records # arrange the data based on the total number of records (before this it was organized alphabetically) job_df = arrange(.data = job_df, -total_records) # print out the head of job_df head(job_df) ## # A tibble: 6 x 2 ## JOB_TITLE total_records ## &lt;fct&gt; &lt;int&gt; ## 1 PROGRAMMER ANALYST 53745 ## 2 SOFTWARE ENGINEER 30669 ## 3 SOFTWARE DEVELOPER 14042 ## 4 SYSTEMS ANALYST 12314 ## 5 COMPUTER PROGRAMMER 11668 ## 6 BUSINESS ANALYST 9167 Now, let’s use ggplot2 to show us what the most popular job titles these visa’s had. ggplot(data = job_df, aes(x = JOB_TITLE, y = total_records)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;aquamarine3&quot;, colour=&quot;black&quot;) + labs(title=&quot;&quot;, x =&quot;Job title (top 50)&quot;, y = &quot;Number of applications&quot;) Hmm…that doesn’t look great. What if we want to swap the X and Y axis? Simple! we just add in a coord_flip() ggplot(data = job_df, aes(x = JOB_TITLE, y = total_records)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;aquamarine3&quot;, colour=&quot;black&quot;) + coord_flip() + labs(title=&quot;&quot;, x =&quot;Job title (top 50)&quot;, y = &quot;Number of applications&quot;) Looks better, but how about we reorder it all based on the total_records column. Just use the reorder function! ggplot(data = job_df, aes(x = reorder(JOB_TITLE,total_records), y = total_records)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;aquamarine3&quot;, colour=&quot;black&quot;) + coord_flip() + labs(title=&quot;2016 H1-B Visa Applications&quot;, x =&quot;Job title (top 50)&quot;, y = &quot;Number of applications&quot;) The most frequent titles are BUSINESS ANALYST, PROGRAMMER ANALYST, and SYSTEMS ANALYST. 7.4 Recap For loops are a popular coding practice and can be very useful. In R, for loops are designed to look like for (numbers or values to loop over){ condition where numbers/values is looping } paste0() is great for combining character strings and numbers together R is great for big data (visa_df is ultimately 647,000 rows of data) dplyr and tibble are once again great R packages for handling big data 7.5 Visa 1 Assignment List the top 10 states who apply for this H1-B Visa Application. In the last example above, we examined the JOB_TITLE variable and discovered the most popular jobs. For this assignment, examine the most popular employers. In other words, create a ggplot instance of the top 50 repeat employers who apply for the H1-B Visa. Try and make it similar to the plot below ## Selecting by total_records "],
["us-work-visas-part-2.html", "8 US Work Visas - Part 2 8.1 Revisiting the H1-B Visa Dataset 8.2 Full Time Positions 8.3 Applications by State 8.4 Prevailing Wage by Location 8.5 Recap 8.6 Assignment", " 8 US Work Visas - Part 2 In this tutorial, we’ll be exploring the H1-B Visa. The H-1B is a visa in the United States which allows U.S. employers to employ foreign workers in specialty occupations. We’ll examine what kind of foreign workers are most often employed. Goals of this tutorial Introduce advanced plotting routines Further explore the H1-B visa dataset Focus on spatial distribution of applications Practice dplyr and tibble Datasets used h1bvisa_part1.csv h1bvisa_part2.csv h1bvisa_part3.csv h1bvisa_part4.csv h1bvisa_part5.csv h1bvisa_part6.csv h1bvisa_part7.csv 8.1 Revisiting the H1-B Visa Dataset We’re already familiar with this dataset from last week, so let’s dive right in from where we left off. # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) library(leaflet) library(lubridate) library(cowplot) library(dplyr) library(readr) library(stringr) # set the path csv_path = &quot;datasets/visa_data/&quot; # list all files within that path csv_list = list.files(path=csv_path, full.names = TRUE) csv_list ## [1] &quot;datasets/visa_data//h1bvisa_part1.csv&quot; ## [2] &quot;datasets/visa_data//h1bvisa_part2.csv&quot; ## [3] &quot;datasets/visa_data//h1bvisa_part3.csv&quot; ## [4] &quot;datasets/visa_data//h1bvisa_part4.csv&quot; ## [5] &quot;datasets/visa_data//h1bvisa_part5.csv&quot; ## [6] &quot;datasets/visa_data//h1bvisa_part6.csv&quot; ## [7] &quot;datasets/visa_data//h1bvisa_part7.csv&quot; # Read all csv files in the folder and create a list of dataframes ldf &lt;- lapply(csv_list , read.csv) # Combine each dataframe in the list into a single dataframe visa_df &lt;- do.call(&quot;rbind&quot;, ldf) # str_split or string split is a great function to use. It breaks up a string based on a character. In this case we want to split our string into a list of cities and states which are split by a comma worksites = str_split(visa_df$WORKSITE, &quot;,&quot;, simplify = TRUE) head(worksites) ## [,1] [,2] ## [1,] &quot;ANN ARBOR&quot; &quot; MICHIGAN&quot; ## [2,] &quot;PLANO&quot; &quot; TEXAS&quot; ## [3,] &quot;JERSEY CITY&quot; &quot; NEW JERSEY&quot; ## [4,] &quot;DENVER&quot; &quot; COLORADO&quot; ## [5,] &quot;ST. LOUIS&quot; &quot; MISSOURI&quot; ## [6,] &quot;MIAMI&quot; &quot; FLORIDA&quot; # grab the second column which is just the states states = worksites[,2] head(states) ## [1] &quot; MICHIGAN&quot; &quot; TEXAS&quot; &quot; NEW JERSEY&quot; &quot; COLORADO&quot; &quot; MISSOURI&quot; ## [6] &quot; FLORIDA&quot; # Now we can use the trimws() function to trim the whitespace and get rid of the leading spaces states = trimws(states) # now add it to the dataframe visa_df$states &lt;- states ## Warning in instance$preRenderHook(instance): It seems your data is too big ## for client-side DataTables. You may consider server-side processing: https:// ## rstudio.github.io/DT/server.html 8.2 Full Time Positions What percentage is full time vs part time? # filter the data where there is data under FULL_TIME_POSITION (i.e. get rid of values that are NA) pos_df = filter(.data = visa_df, !is.na(FULL_TIME_POSITION)) # group the data by the FULL_TIME_POSITION pos_df = group_by(.data=pos_df, FULL_TIME_POSITION) # summarize the data based on the total number of recrods pos_df = summarise(.data = pos_df,total_records = length(lat)) # what does pos_df look like pos_df ## # A tibble: 2 x 2 ## FULL_TIME_POSITION total_records ## &lt;fct&gt; &lt;int&gt; ## 1 N 351146 ## 2 Y 296662 Alright, we have the total number of records for both Full time and Part Time position. What’s the percentage breakdown between the two? To answer this specific question, a pie chart might be useful. Luckily, a package called plotrix has a function called pie3D which can be used to accomplish this task. library(plotrix) # create a list of our unique labels - Part time is first because it&#39;s the first row in pos_df (aka where the answer to full time position is N) lbls = c(&quot;Part time&quot;,&quot;Full time&quot;) # calculte the perdentage pcts = round(pos_df$total_records / sum(pos_df$total_records) * 100) # note that we use paste here and not paste0, remember that the 0 means 0 spaces between lbls = paste(lbls, pcts) lbls ## [1] &quot;Part time 54&quot; &quot;Full time 46&quot; # now let&#39;s add a % sign in lbls = paste(lbls,&quot;%&quot;, sep=&quot;&quot;) lbls ## [1] &quot;Part time 54%&quot; &quot;Full time 46%&quot; # create a list of the colors we want here cols = c(&quot;aquamarine3&quot;, &quot;indianred&quot;) pie3D(x=pos_df$total_records, labels=lbls, col = cols, explode=0, main = &quot;H1-B Visa Positions type&quot;) There are more part time positions rather than fulltime for this dataset. pie3D can be a useful, quick way to create a piechart. 8.3 Applications by State How does the number of total applications vary by state? What’s a good way to visualize this? We can use dplyr to separate out the total applications by state. We’ll have to use our states variable that we included with teh dataset above. # filter out the NA data state_df = filter(.data = visa_df, !is.na(states)) # group the dataframe by states state_df = group_by(.data = state_df, states) # create a summary per state by counting the total number of cases for each state state_df = summarise(.data = state_df, total_records = length(CASE_STATUS)) # Normalize the data by dividing by 1000 state_df$total_records &lt;- state_df$total_records/1000 #remember we can change the name of our columns if we want to colnames(state_df) &lt;- c(&quot;state&quot;,&quot;value&quot;) # use the treemap function from the treemap package to create the plot library(treemap) treemap(state_df, index=c(&quot;state&quot;), type=&quot;value&quot;, vSize = &quot;value&quot;, vColor=&quot;value&quot;, palette = &quot;RdBu&quot;, title=&quot;H1-B Visa Applications per State(thousands)&quot;, fontsize.title = 14 ) treemaps are great for visualizing data like this. Both the color and the total amount of space taken up in the image are correlated to the total amount of applications by state. Notice that the arguments for the treemap are a little different than ggplot2. treemap is not part of tidyverse, but still can be used with any data frame (as with most things in R). 8.4 Prevailing Wage by Location Let’s investigate another type of plot that R is capable of creating - a leaflet interactive plot. We’ll dive into this but first we’ll need to manipulate the data. Remember the lat/lon rounding we did? Let’s do that again only let’s round it down to 1/1000th decimal place. visa_df$lat = round(visa_df$lat,3) visa_df$lon = round(visa_df$lon,3) Now let’s filter our dataset, group it by lat and lon, and then take the mean of the PREVAILING WAGE variable. # filter out the NA values of the `lat` variable wage_df = filter(.data = visa_df, !is.na(lat)) # filter out the NA values of the `lon` variable wage_df = filter(.data = wage_df, !is.na(lon)) # filter for cases where the CASE_STATUS is CERTIFIED wage_df = filter(.data = wage_df, CASE_STATUS == &quot;CERTIFIED&quot;) # group by the lat AND lons (for times when the same company (aka same lat/lon) has multiple applications) wage_df = group_by(.data = wage_df, lat,lon) # summarize the data by taking the average PREVAILING WAGE wage_df = summarise(.data = wage_df, avg = mean(PREVAILING_WAGE)) # create the bins in which our color palette will have corresponding values bins &lt;- c(min(wage_df$avg),50000, 100000, 150000, 200000 ,max(wage_df$avg)) # create a custom color palette using pre-exisitng paletes and then coloring in the values based on the bins above # note that we use the premade color palette &quot;RdYlGn&quot; in R. pal &lt;- colorBin(&quot;RdYlGn&quot;, domain = wage_df$avg, bins = bins) # using leaflet which involves PIPING leaflet(data = wage_df) %&gt;% addTiles() %&gt;% setView(-99, 35, zoom = 4) %&gt;% addCircleMarkers( lat=wage_df$lat, lng=wage_df$lon, radius=sqrt(wage_df$avg)/20, color = ~pal(wage_df$avg), weight=1.5, opacity=0.8, popup= paste(&quot;Average Wage $&quot;, round(wage_df$avg/1000), &quot;k&quot;) ) There we have it, a beautiful and interactive map showing average wage for by location. leaflet is a powerful tool to visualize spatial data. The key here with leaflet is that with ggplot we can use the + sign to add additional arguments/functionality to a plot. With leaflet, we need to use the pipe operator - %&gt;%. Remember, the pipe operator can be though of as sending or passing along information. In this case we create a leaflet instance with leaflet(data=wage_df). We pipe that over to the leaflet function addTiles(). This creates the map. Then we set the view of the image as setView and then pipe that to the leaflet function as addCircleMarkers. This is the most advanced function with the leaflet package as we can add in a ton of functionality. An important note here is that for the color argument, we are using our pre-made color palette pal. 8.5 Recap Although we’ve spent a good bit of time with the most popular plotting package (ggplot2), there are other plotting packages in R that can be very useful The treemap package is useful for showing concentrations and distributions of a particular variable leaflet is a powerful interactive plotting package that’s great for spatial maps - leaflet uses the pipe operator %&gt;% R has many premade color palettes that are useful - more can be found here 8.6 Assignment What state is offering the highest average wage? What about the lowest? Create a treemap of the average prevailing wage by state. Where are the applications primarily coming from? Create a leaflet plot of the applications by location. First, round the lat/lon values to the 2nd decimal place. Then, plot your leaflet! You’ll want your resulting plots to look something like… "]
]
