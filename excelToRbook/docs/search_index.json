[
["welcome.html", "Tech Trainings - From Excel to R 1 Welcome 1.1 Agenda", " Tech Trainings - From Excel to R James Simkins 2020-09-08 1 Welcome Hello! Welcome to Tech Trainings - From Excel to R. We’re here to enhance the productivity of your business by ditching Excel and employing R. Our tutorials are focused and designed for employees currently working. R is currently ranked as the 7th most popular language in the world - and with good reason! We’ll dive into why R is ranked so high and how it can benefit you and your business. This intro to R course is designed to teach R to businesses and employees who frequently use Excel for day-to-day operations. Few businesses around the world leverage the amazing features of R and we’re here to teach these skills. To put it bluntly, R saves you and your employees a ton of time. We’ve seen users cut down daily 2-3 hour tasks in Excel into 2-3 minutes after some basic introduction to R. In this case, R saved this individual employee 750 hours per year - allowing employee time to be used towards more creative problem-solving endeavors. This is a concentrated, fast-paced course designed to improve business efficiency, cut down tedious tasks, and increase the creative time spent by employees. Most online R tutorials are far too broad and can leave a student frustrated at the vast abilities of R. R can be used to accomplish a great deal, but instead of showing off what R can do, we discuss and teach select skills that can be used to improve day-to-day business efficiency immediately. We’re not here to waste your time and overwhelm our students like other R workshops. This concentrated course follows a design of specific problem solving. We present common business practices often handled using Excel and show an employee can use R to accomplish the same task at a faster pace. The workshop is split into 5 days with assignments due each day. This course was developed by James Simkins who has taught multiple programming courses at the University of Delaware. 1.1 Agenda This course is designed to be a 5 day course intended to teach R to Excel Users. The intended time per day is 2-3 hours. Day Focus 1 Overview 2 Avacado Tutorial 1 3 Avacado Tutorial 2 4 Visa Tutorial 1 5 Visa Tutorial 2 "],
["getting-started-with-r.html", "2 Getting Started with R 2.1 Why is there such a buzz around R? 2.2 Reasons to love R 2.3 Downloading Guide 2.4 Rstudio 2.5 Download Workshop Datasets 2.6 Video Examples 2.7 Getting familiar with RStudio 2.8 Open RStudio 2.9 R Studio Layout", " 2 Getting Started with R 2.1 Why is there such a buzz around R? R is an open-source programming language used for data science, statistics, and data visualization. R is currently ranked as the 7th most popular language in the world. Since R is open-source, anyone can contribute to or use R packages that contain pre-built functions/operations. This greatly accelerates our ability to share and collaborate. The purpose of this workshop is to teach working professionals how to use R for tasks they’d normally use Excel for. Excel is a powerful tool and is great for a variety of uses, but when it comes to crunching data, R will greatly improve the speed at which these tasks can be done. Furthermore, with R, mundane &amp; tedious tasks can be automated. When you write a script in R for a recurring task such as calculating a monthly budget, all one needs to do each month is provide the routine with a new dataset to crunch the numbers. Below are examples of why we use R. 2.2 Reasons to love R Attribute Reason Speed R is FAST. It can number crunch magnitudes faster than Microsoft Excel, for example. Capacity R can handle millions of data records. Large datasets that crash in Microsoft Excel won’t crash in R. Risk Reduction After writing a single R Script, the process of your data science routine is auditable and reproducible within milliseconds. We can write 1 script and make alterations as we see fit. We don’t have to replicate a process of pointing and clicking in Microsoft Excel or ArcGIS. For example, if you are working with a dataset that multiple people are using, you can load this dataset in R and perform the tasks that you need without making any changes to the original dataset. Visualizations R is capable to create high quality visualizations and also has the capacity to create interactive visualizations that can easiliy be shared. Plots or images can easily be exported to PNG, JPEG, or even web-based interactive dashboards that can be hosted on a webpage Collaboration R script sharing is safe and easy. As mentioned above, a team using the same data input file but performing different tasks on it can do so without editing the data input file for everyone else. Data output can also be shared without the concern of a colleague editing the file output. RStudio connect or Github are also popular free track all changes that take place between R script files. Price R is completely free! Yes…every bit of it! 2.3 Downloading Guide Navigate to the R website: https://cloud.r-project.org/ Click Download for your Operating System (Windows, Mac OSx, or Linux - if you don’t have a MacBook, then you’re using Windows most likely) Click the most recent R version to download. Install the downloaded application as you would with any other application on your computer. 2.4 Rstudio While R is the language, RStudio is the application we use to run R. Technically speaking, RStudio is an integrated development environment for R. RStudio makes coding in R easier by highlighting syntax, autocompleting symbols and names, and visualizing our R environment. These aspects are explained in further detail in the R Coding Fundamentals section. For now, let’s download RStudio. Navigate to the RStudio Website: http://www.rstudio.com/download Click Download under RStudio Desktop Free This website detects your operating system, allowing you to just click download again. Note that if it doesn’t automatically detect just select the download next to your operating system below this Note that you may be asked to install command line developer tools if you’re using a Mac - select Yes. Install the downloaded application as you normally would on your computer. 2.5 Download Workshop Datasets Navigate to the database - https://github.com/jsimkins2/dataforge Click on Code - then click download as zip 2.6 Video Examples If you want to watch a step-by-step tutorial on how to install R for Mac or Windows, you can watch these videos courtest of Dr. Roger Peng Installing R on Windows Installing R on the Mac Installing RStudio 2.7 Getting familiar with RStudio By now you’ve downloaded R and RStudio and you’re probably wondering, why do I need to download both? R is that programming language that is running on your computer. RStudio is what we call an Indegrated Development Environment (IDE) - this is a technical term for a pretty application that’s all dressed up on the surface but underneath is really crunching some numbers (using R) at serious speeds. RStudio is the application we’ll be using. Let’s open RStudio and get familiar with it. 2.8 Open RStudio Navigate to your applications folder on your computer. Launch RStudio. When you open it for the first time, you should see this. This is RStudio. When you open it for the first time, we’ll need to open a new RScript to begin coding. Open new R Script To open a new R Script, we select the blankpage with green plus icon and select R Script from the menu. This opens up the new R script and we can begin coding in R. Now that we have the R Script open, you’ll notice 4 quadrants. Let’s run through what those quadrants are. 2.9 R Studio Layout Now let’s describe what’s going on here in a little more detail. R Script - This is your canvas. This is where we write and edit our code. A lot of trial and error goes on here. R Console - This is where you run your code. When we talk about running code, we mean we’re telling R to execute the code we’ve written in the R Script. R Console is the place inside RStudio where we are using the R programming language. Variable Environment - This area keeps track of your variables, data tables, filenames, etc. Anything that you run in R that has a name will be stored here. Imagine the Variable Environment to be your closet - every time you make/buy a new sweater, the sweater goes in the closet. We can select data tables to view from this list here. Files/Plots/Help - In this quadrant, we can toggle through files on our computer (we can view where your files are stored), view plots/visualizations that we’re creating in R (whenever you create a plot in R it is output here first), search for help and descriptions of R functions (there’s descriptions on every function you’ll use in R - they can all be loaded here in the help tab), and more. "],
["definitions-rules.html", "3 Definitions &amp; Rules 3.1 Important R Programming Definitions 3.2 Rules 3.3 General Recommendations", " 3 Definitions &amp; Rules This is a reference guide to look back on when you’re stuck. These definitions and rules are not expected to be understood right now but it’s important you know you can look back on this as a quick-reference. 3.1 Important R Programming Definitions Read through these now to get familiar and refer back to these whenever you need a refresher. You’re not expected to have these memorized or even understood at this moment. These will make more sense as we progress through the course. Coding Name Example Definition syntax R code the nomenclature and structure of a programming language debugging Failed R run debugging involves fixing R code that is written incorrectly and doesn’t run variable my_var Variables are used to store data, whose value can be changed according to our need. Variables can be declared using &lt;- (tradiational way) or by = (conventional way) package library(ggplot2) A collection of functions prewritten in R function print() A function is a set of statements organized together to perform a specific task. R has a set of preloaded functions that are part of the base package. If a function cannot be found as part of the base package, the function has likely already been built under another package that needs to be loaded in. Functions can be identified due to their enclosing parantheses () arguments read.csv(file = &quot;datasets/avocados.csv&quot;, header = FALSE) Components of a function that are separated by commas and declared using the = sign. Arguments in this example are file = and header = index mtcars[3,5] The position of data within a data frame, matrix, list, vector, etc. In R, data is indexed as [row,column] and indexing is done via brackets [] loop for (n in names){print(n)} Repeats a task for a specified number of times. Saves a programmer from repeating codelines with different parameters. logical TRUE, FALSE TRUE and FALSE logical operators are declared using all caps arithmetic operators +,-,*,/,^ Math operators used for addition, subtraction, multiplication, division, exponent, respectively. comparison operators ==, &lt;, &gt;, &lt;=, &gt;=, != Is equal to, less than, greater than, less than or equal to, greater than or equal to, is NOT equal to, respectively and/or operators &amp;, | AND, OR string a_string = &quot;anythign within quotes, single or double&quot; Any value written within a pair of single quote or double quotes in R is treated as a string. numeric 1 Any number - integer, float, etc. vector as.vector(x = c(1,2,3,4)) Vectors are the most basic R data objects and there are six types of atomic vectors. They are logical, integer, double, complex, character and raw. lists list('Peter', 'Sarah', 'Tom', 'Helen') Lists are the R objects which contain elements of different types like − numbers, strings, vectors and another list inside it matrix matrix(c(1:5), nrow = 3, byrow = TRUE) Matrices are the R objects in which the elements are arranged in a two-dimensional rectangular layout. array array(data = c(1,2,3)) Arrays are the R data objects which can store data in more than two dimensions. For example − If we create an array of dimension (1, 2, 3) then it creates 3 rectangular matrices each with 1 rows and 2 columns. Arrays can store only one data type. data frame data.frame(mtcars) R version of Excel Spreadsheet. A data frame is a table or a two-dimensional array-like structure in which each column contains values of one variable and each row contains one set of values from each column. factor factor() Factors are the data objects which are used to categorize the data and store it as levels. They can store both strings and integers. They are useful in the columns which have a limited number of unique values. Like “Male,”Female&quot; and True, False etc. They are useful in data analysis for statistical modeling. help help(mean) or ?mean Default helper function in R. Opens up documentation on a particular function in the lower right quadrant of R. class class(mtcars$mpg) Tells us what R is recognizing something as concatenate (c) c(“a”, “b”, “c”) A quick utility for concatenating strings together filepath “/Users/james/Downloads/” The location on your computer where a file is stored. A filepath with a leading slash (akak “/” ) is also referred to as root. Root is the furthest back you can go on your computer. Think of a filepath like this - “/Earth/UnitedStates/Pennsylvania/Lancaster/” Additional examples can be found here 3.2 Rules Variable names must be assigned. names_list &lt;- list(&#39;Peter&#39;, &#39;Sarah&#39;, &#39;Tom&#39;, &#39;Helen&#39;) # is the Comment Operator - anything on the same line of the # comment operator will not be run by R. # comments can be above names_list &lt;- list(&#39;Peter&#39;, &#39;Sarah&#39;, &#39;Tom&#39;, &#39;Helen&#39;) # comments can be outside ## comments can be anywhere. Parantheses (), Brackets [], Curly brackets {}, Quotations &quot;&quot; must be used in pairs names_list = list(&#39;Peter&#39;, &#39;Sarah&#39;, &#39;Tom&#39;, &#39;Helen&#39;) for (n in names_list){ print(n) } If you don’t have a package, you must install that package. (After you install once, you don’t need to install again.) install.packages(&#39;ggplot2&#39;) Packages MUST be loaded for each R session. library(ggplot2) Variable names should not replicate function/package names. ## don&#39;t do this mean = mean(c(1,2,3)) ## do NOT do this ## DO this instead my_mean = mean(c(1,2,3)) ## do this instead 3.3 General Recommendations Comment, comment, comment. A comment is a brief note on what you were doing when you wrote a line of code. For example, if you write some R code that edits part of a dataframe (R’s version of an Excel Spreadsheet), comment what you were thinking here and why you did it this way. Once you become comfortable coding in R, you’ll be able to churn out new R scripts at a faster rate. It’s very important that you comment on what you’re doing at each step in the script so if you need to look back on something you wrote you can reference what you were doing there. A comment in R is declared using the pound symbol (#). Keep raw data raw. An advantage of R is being able to read in an original spreadsheet and output a new spreadsheet as a separate file. In other words, when you read in a dataset (for example, avocados.csv) and make changes to this file, do not save it was avocados.csv - thus overwriting the file. Instead, name it something like avocados_edited.csv. Also, notice how we use underscores (_) in between words of a filename - this is good practice that should be replicated (spaces are bad, see 4) When in doubt, Google your R question - look for StackOverflow links. StackOverflow is a web-forum where programmers can post questions for help. This is an incredible tool that even advanced programmers and developers use daily. There are other helpful forums out there - StackOverflow is the most popular. Spaces in variable/file names are BAD. A variable is an object or column that you create in R. For example, if you have a list of student names (student_names = list(&quot;John&quot;, &quot;Peter&quot;, &quot;Sebastian&quot;), the variable here would be student_names. Let’s get into the habit of using underscores ’_’ or dashes ‘-’ or periods ‘.’ to separate words instead of spaces. From the computers side of variable name storage, it’s much safer to declare a variable name such as data_file as opposed to data file Keep in mind, these will make more sense after we get more familiar with R - it’s alright if they’re confusing right now! "],
["r-coding-fundamentals.html", "4 R Coding Fundamentals 4.1 Entering Input 4.2 Running Code 4.3 Evaluation 4.4 Packages and Functions 4.5 Arguments 4.6 R Objects 4.7 Creating Vectors 4.8 Mixing Objects 4.9 Changing Classes 4.10 Missing Values 4.11 Attributes 4.12 Matrices 4.13 Lists 4.14 Factors 4.15 Data Frames 4.16 Names 4.17 Summary", " 4 R Coding Fundamentals Now that we’re comfortable with R Studio and have some definitions under our belt, let’s dive in a little into some R code and discuss it. These fundamentals can always be referred back to when we might be stuck coding later on. 4.1 Entering Input In the R Script area, we write code. Whenever we want to assign a variable, we do so using the assignment operator. The &lt;- symbol is the assignment operator. We can also use = which is a bit more intuitive. It is alright to interchange these when assigning variables. val &lt;- 1 print(val) ## [1] 1 val ## [1] 1 msg &lt;- &quot;hello&quot; val and msg are both variables that we assigned. We use the # character to write comments inside our code. Commented code is NOT executed by R. x &lt;- ## Incomplete expression Anything to the right of the # (including the # itself) is ignored. 4.2 Running Code After placing the above code in your R Script area, we can run the code. Code execution is done in the R Console. We can “send” our code in the R Script to the R Console using the Run Button, ctrl + enter (Windows), or cmd + enter (Mac). We can select specific lines of code to run, larger chunks, or the entire R Script. 4.3 Evaluation When a complete expression is entered at the prompt, it is evaluated and the result of the evaluated expression is returned. The result may be auto-printed. val &lt;- 14 ## nothing printed val ## auto-printing occurs ## [1] 14 print(val) ## explicit printing ## [1] 14 The [1] shown in the output indicates that x is a vector and 14 is its first element. Typically we do not explicitly print variables since auto-printing is easier. When an R vector is printed you will notice that an index for the vector is printed in square brackets [] on the side. For example, see this integer sequence of length 10. my_seq &lt;- 10:20 my_seq ## [1] 10 11 12 13 14 15 16 17 18 19 20 Notice the [1] that preceeds the sequence. The output inside the square bracket is not part of the vector itself, it’s just part of the printed output that has additional information to be more user-friendly. This extra information is not part of the object itself. Also note that we used the : operator to create a sequence of integers from 10 to 20 (10:20). Note that the : operator is used to create integer sequences. 4.4 Packages and Functions In R, a package is a collection of functions. A function is a tool you can use to do something. In other words, imagine a package as a toolbox and functions as the tools within the toolbox. If we want to load the wrenches toolbox, we can load it like so - library(wrenches). Then, we can use different wrenches from that toolbox like - small_wrench(), medium_wrench(), big_wrench(). In R, a base package is automatically loaded in for you. Within the base package, we can find common functions such as mean(), min(), max(), etc. We can also find mathematical functions such as log(), sin(), cos(), etc. Even though it’s redundant, let’s load the base package. library(base) my_seq &lt;- 10:20 mean(my_seq) ## [1] 15 The mean of our sequence of numbers (stored as the object my_seq) is 15. It printed this out automatically due to the fact that we didn’t store it as an object. library(base) my_seq = 10:20 my_mean = mean(my_seq) my_mean ## [1] 15 Now, we stored the mean of our my_seq as my_mean. This object can now be found in our global environment (top right quadrant) and is recognized by R. Notice how I used the = assignment operator as opposed to &lt;-. Either can be used when assigning an object in R. Also, how do we know something is a function in R? Because of the () parentheses following the function name mean(). 4.5 Arguments Functions have changeable parameters called arguments. These arguments must be declared using the = operator and they are always separated by a comma. Let’s take a look at the sequence function seq() by running the following help() (you can also run ?seq. help(seq) Notice that we have arguments from, to, by, length.out, and along.with. These arguments are pre-definded, meaning if you don’t declare the values for the arguments, the function will automatically have arguments declared for you. my_seq &lt;- seq(from = 50, to = 100, by = 10) my_seq ## [1] 50 60 70 80 90 100 We declared our from, to, and by arguments here to create this new sequence of numbers from 50 to 100 spaced by 10. We declared the arguments using the = operator and separated them via a comma. Let’s try something different now… my_seq &lt;- seq(50,100,10) my_seq ## [1] 50 60 70 80 90 100 The same result. Even though I didn’t explicitly declare the functions, R assumed I was declaring arguments from, to, and by with the numbers separated by commas. This is called shorthand argument declaration. If you’re going to use shorthand argument delcaration, the order of the arguments must match the order they are listed in the function. However, if we explicitly declare our functions, we can use whatever order we want. my_seq &lt;- seq(by = 10, to = 100, from = 50) my_seq ## [1] 50 60 70 80 90 100 4.6 R Objects R has five basic classes of objects: character numeric (real numbers) integer complex logical (True/False) The most basic type of R object is a vector. Empty vectors can be created with the vector() function. There is really only one rule about vectors in R, which is that A vector can only contain objects of the same class. But of course, like any good rule, there is an exception, which is a list, which we will get to a bit later. A list is represented as a vector but can contain objects of different classes. Indeed, that’s usually why we use them. 4.7 Creating Vectors The c() function is referred to as the concatenate (combine) function. Using this, we can create vectors of objects by combining them together. x &lt;- c(1.25, 2.50) ## numeric x &lt;- c(TRUE, FALSE) ## logical x &lt;- c(T, F) ## logical x &lt;- c(&quot;yes&quot;, &quot;no&quot;, &quot;maybe&quot;) ## character x &lt;- 25:44 ## integer x &lt;- c(1+2i, 3+8i) ## complex Note that in the above example, T and F are short-hand ways to specify TRUE and FALSE. However, in general one should try to use the explicit TRUE and FALSE values when indicating logical values. 4.8 Mixing Objects There are occasions when different classes of R objects get mixed together. Sometimes this happens by accident but it can also happen on purpose. So what happens with the following code? y &lt;- c(1.7, &quot;a&quot;) ## character y &lt;- c(TRUE, 2) ## numeric y &lt;- c(&quot;a&quot;, TRUE) ## character In each case above, we are mixing objects of two different classes in a vector. But remember that the only rule about vectors says this is not allowed. When different objects are mixed in a vector, coercion occurs so that every element in the vector is of the same class. In the example above, we see the effect of implicit coercion. What R tries to do is find a way to represent all of the objects in the vector in a reasonable fashion. Sometimes this does exactly what you want and…sometimes not. For example, combining a numeric object with a character object will create a character vector, because numbers can usually be easily represented as strings. 4.9 Changing Classes Objects can be explicitly coerced from one class to another using the as.* functions. In other words, you can change the class of one thing to another via the as.* functions. x &lt;- 0:10 class(x) ## [1] &quot;integer&quot; as.numeric(x) ## [1] 0 1 2 3 4 5 6 7 8 9 10 as.logical(x) ## [1] FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE as.character(x) ## [1] &quot;0&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; x &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) as.numeric(x) ## Warning: NAs introduced by coercion ## [1] NA NA NA as.logical(x) ## [1] NA NA NA as.complex(x) ## Warning: NAs introduced by coercion ## [1] NA NA NA 4.10 Missing Values In certain datasets, you’ll find values called NA or NaN. NA is short for Not Available, NaN is short forNot a Number . This is equivalent to a blank grid cell in Microsoft Excel. is.na() is used to test objects if they are NA is.nan() is used to test for NaN NA values have a class also, so there are integer NA, character NA, etc. A NaN value is also NA but the converse is not true x = c(1,2,NA,NaN,5) is.na(x) ## [1] FALSE FALSE TRUE TRUE FALSE is.nan(x) ## [1] FALSE FALSE FALSE TRUE FALSE mean(x) ## [1] NA Sometimes, R will return NA. This can mean we haven’t given R every argument it needs to accomplish a task, we have used an incorrect function, we have given R an incomplete dataset, or we haven’t removed NAs from a calculation like mean(). Note that if you run help(mean) or ?mean(), you’ll see a logical argument called na.rm. mean(x, na.rm = TRUE) ## [1] 2.666667 4.11 Attributes R objects can have attributes, which are like metadata for the object. These metadata can be very useful in that they help to describe the object. For example, column names on a data frame help to tell us what data are contained in each of the columns. Some examples of R object attributes are names, dimnames dimensions (e.g. matrices, arrays) class (e.g. integer, numeric) length other user-defined attributes/metadata Attributes of an object (if any) can be accessed using the attributes() function. Not all R objects contain attributes, in which case the attributes() function returns NULL. 4.12 Matrices Matrices are vectors with a dimension attribute. The dimension attribute is itself an integer vector of length 2 (number of rows, number of columns) m &lt;- matrix(nrow = 2, ncol = 3) m ## [,1] [,2] [,3] ## [1,] NA NA NA ## [2,] NA NA NA dim(m) ## [1] 2 3 attributes(m) ## $dim ## [1] 2 3 Matrices are constructed column-wise, so entries can be thought of starting in the “upper left” corner and running down the columns. m &lt;- matrix(1:6, nrow = 2, ncol = 3) m ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 Matrices can also be created directly from vectors by adding a dimension attribute. m &lt;- 1:10 m ## [1] 1 2 3 4 5 6 7 8 9 10 dim(m) &lt;- c(2, 5) m ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 3 5 7 9 ## [2,] 2 4 6 8 10 Matrices can be created by column-binding or row-binding with the cbind() and rbind() functions. x &lt;- 1:3 y &lt;- 10:12 cbind(x, y) ## x y ## [1,] 1 10 ## [2,] 2 11 ## [3,] 3 12 rbind(x, y) ## [,1] [,2] [,3] ## x 1 2 3 ## y 10 11 12 4.13 Lists Lists are a special type of vector that can contain elements of different classes. Lists are a very important data type in R and you should get to know them well. Lists, in combination with the various “apply” functions discussed later, make for a powerful combination. Lists can be explicitly created using the list() function, which takes an arbitrary number of arguments. x &lt;- list(1, &quot;a&quot;, TRUE) x ## [[1]] ## [1] 1 ## ## [[2]] ## [1] &quot;a&quot; ## ## [[3]] ## [1] TRUE We can also create an empty list of a prespecified length with the vector() function x &lt;- vector(&quot;list&quot;, length = 5) x ## [[1]] ## NULL ## ## [[2]] ## NULL ## ## [[3]] ## NULL ## ## [[4]] ## NULL ## ## [[5]] ## NULL 4.14 Factors Factors are used to represent categorical data and can be unordered or ordered. One can think of a factor as an integer vector where each integer has a label. Using factors with labels is better than using integers because factors are self-describing. Having a variable that has values “Male” and “Female” is better than a variable that has values 1 and 2. Factor objects can be created with the factor() function. x &lt;- factor(c(&quot;yes&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;)) x ## [1] yes yes no yes no ## Levels: no yes table(x) ## x ## no yes ## 2 3 ## See the underlying representation of factor unclass(x) ## [1] 2 2 1 2 1 ## attr(,&quot;levels&quot;) ## [1] &quot;no&quot; &quot;yes&quot; Often factors will be automatically created for you when you read a dataset in using a function like read.table(). Those functions often default to creating factors when they encounter data that look like characters or strings. The order of the levels of a factor can be set using the levels argument to factor(). This can be important in linear modelling because the first level is used as the baseline level. x &lt;- factor(c(&quot;yes&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;)) x ## Levels are put in alphabetical order ## [1] yes yes no yes no ## Levels: no yes x &lt;- factor(c(&quot;yes&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;), levels = c(&quot;yes&quot;, &quot;no&quot;)) x ## [1] yes yes no yes no ## Levels: yes no 4.15 Data Frames Data frames are used to store tabular data in R. They are an important type of object in R and are used in a variety of statistical modeling applications. We’ll be working with many dataframes throughout these tutorials. Data frames are represented as a special type of list where every element of the list has to have the same length. Each element of the list can be thought of as a column and the length of each element of the list is the number of rows. Unlike matrices, data frames can store different classes of objects in each column. Matrices must have every element be the same class (e.g. all integers or all numeric). In addition to column names, indicating the names of the variables or predictors, data frames have a special attribute called row.names which indicate information about each row of the data frame. Data frames are usually created by reading in a dataset using the read.table() or read.csv(). However, data frames can also be created explicitly with the data.frame() function or they can be coerced from other types of objects like lists. Data frames can be converted to a matrix by calling data.matrix(). While it might seem that the as.matrix() function should be used to coerce a data frame to a matrix, almost always, what you want is the result of data.matrix(). x &lt;- data.frame(foo = 1:4, bar = c(T, T, F, F)) x ## foo bar ## 1 1 TRUE ## 2 2 TRUE ## 3 3 FALSE ## 4 4 FALSE nrow(x) ## [1] 4 ncol(x) ## [1] 2 4.16 Names R objects can have names, which is very useful for writing readable code and self-describing objects. Here is an example of assigning names to an integer vector. x &lt;- 1:3 names(x) ## NULL names(x) &lt;- c(&quot;New York&quot;, &quot;Seattle&quot;, &quot;Los Angeles&quot;) x ## New York Seattle Los Angeles ## 1 2 3 names(x) ## [1] &quot;New York&quot; &quot;Seattle&quot; &quot;Los Angeles&quot; Lists can also have names, which is often very useful. x &lt;- list(&quot;Los Angeles&quot; = 1, Boston = 2, London = 3) x ## $`Los Angeles` ## [1] 1 ## ## $Boston ## [1] 2 ## ## $London ## [1] 3 names(x) ## [1] &quot;Los Angeles&quot; &quot;Boston&quot; &quot;London&quot; Matrices can have both column and row names. m &lt;- matrix(1:4, nrow = 2, ncol = 2) dimnames(m) &lt;- list(c(&quot;a&quot;, &quot;b&quot;), c(&quot;c&quot;, &quot;d&quot;)) m ## c d ## a 1 3 ## b 2 4 Column names and row names can be set separately using the colnames() and rownames() functions. colnames(m) &lt;- c(&quot;h&quot;, &quot;f&quot;) rownames(m) &lt;- c(&quot;x&quot;, &quot;z&quot;) m ## h f ## x 1 3 ## z 2 4 Note that for data frames, there is a separate function for setting the row names, the row.names() function. Also, data frames do not have column names, they just have names (like lists). So to set the column names of a data frame just use the names() function. Yes, I know its confusing. Here’s a quick summary: Object Set column names Set row names data frame names() row.names() matrix colnames() rownames() 4.17 Summary There are a variety of different builtin-data types in R. In this chapter we have reviewed the following object declaration packages, functions, arguments classes: numeric, logical, character, integer, complex vectors, lists missing values factors missing values data frames and matrices All R objects can have attributes that help to describe what is in the object. Perhaps the most useful attribute is names, such as column and row names in a data frame, or simply names in a vector or list. Attributes like dimensions are also important as they can modify the behavior of objects, like turning a vector into a matrix. The content in this section was adapted from Dr. Roger Peng "],
["r-script-template.html", "5 R Script Template 5.1 Cars - Motor Trends Magazine Data", " 5 R Script Template In this example, we’ll begin with data science question and answer it in R. We’ll go through these scripts line by line to show how we can use R. To follow along, copy each of these lines and paste them in your R Script (top left quadrant). Once it’s pasted there, we can run each line and view the output in the R Console (bottom left quadrant). 5.1 Cars - Motor Trends Magazine Data The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). Load the dataset - again this is a pre-loaded dataset, but let’s call on it so we can bring it into our global environment. data(&#39;mtcars&#39;) head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 The head() function is a quick function that prints out the first few rows of a dataset. What’s exactly is mtcars? class(mtcars) ## [1] &quot;data.frame&quot; It’s a data.frame. Data Frames have a different storage than time series. You can also view this dataframe by clicking on the mtcars dataframe in your global environment. What are the dimensions of this dataframe? How many rows and columns does it have? dim(mtcars) ## [1] 32 11 nrow(mtcars) ## [1] 32 ncol(mtcars) ## [1] 11 We have 32 rows and 11 columns within this dataframe. What are our column names? colnames(mtcars) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; What are our row names (aka the make of the car)? rownames(mtcars) ## [1] &quot;Mazda RX4&quot; &quot;Mazda RX4 Wag&quot; &quot;Datsun 710&quot; ## [4] &quot;Hornet 4 Drive&quot; &quot;Hornet Sportabout&quot; &quot;Valiant&quot; ## [7] &quot;Duster 360&quot; &quot;Merc 240D&quot; &quot;Merc 230&quot; ## [10] &quot;Merc 280&quot; &quot;Merc 280C&quot; &quot;Merc 450SE&quot; ## [13] &quot;Merc 450SL&quot; &quot;Merc 450SLC&quot; &quot;Cadillac Fleetwood&quot; ## [16] &quot;Lincoln Continental&quot; &quot;Chrysler Imperial&quot; &quot;Fiat 128&quot; ## [19] &quot;Honda Civic&quot; &quot;Toyota Corolla&quot; &quot;Toyota Corona&quot; ## [22] &quot;Dodge Challenger&quot; &quot;AMC Javelin&quot; &quot;Camaro Z28&quot; ## [25] &quot;Pontiac Firebird&quot; &quot;Fiat X1-9&quot; &quot;Porsche 914-2&quot; ## [28] &quot;Lotus Europa&quot; &quot;Ford Pantera L&quot; &quot;Ferrari Dino&quot; ## [31] &quot;Maserati Bora&quot; &quot;Volvo 142E&quot; How do we extract individual columns/variables from this dataframe? mtcars[&quot;mpg&quot;] ## mpg ## Mazda RX4 21.0 ## Mazda RX4 Wag 21.0 ## Datsun 710 22.8 ## Hornet 4 Drive 21.4 ## Hornet Sportabout 18.7 ## Valiant 18.1 ## Duster 360 14.3 ## Merc 240D 24.4 ## Merc 230 22.8 ## Merc 280 19.2 ## Merc 280C 17.8 ## Merc 450SE 16.4 ## Merc 450SL 17.3 ## Merc 450SLC 15.2 ## Cadillac Fleetwood 10.4 ## Lincoln Continental 10.4 ## Chrysler Imperial 14.7 ## Fiat 128 32.4 ## Honda Civic 30.4 ## Toyota Corolla 33.9 ## Toyota Corona 21.5 ## Dodge Challenger 15.5 ## AMC Javelin 15.2 ## Camaro Z28 13.3 ## Pontiac Firebird 19.2 ## Fiat X1-9 27.3 ## Porsche 914-2 26.0 ## Lotus Europa 30.4 ## Ford Pantera L 15.8 ## Ferrari Dino 19.7 ## Maserati Bora 15.0 ## Volvo 142E 21.4 We can also extract the vector of data using the $ operator. mtcars$mpg ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 ## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 ## [31] 15.0 21.4 What are the statistics like for each variable? summary(mtcars) ## mpg cyl disp hp ## Min. :10.40 Min. :4.000 Min. : 71.1 Min. : 52.0 ## 1st Qu.:15.43 1st Qu.:4.000 1st Qu.:120.8 1st Qu.: 96.5 ## Median :19.20 Median :6.000 Median :196.3 Median :123.0 ## Mean :20.09 Mean :6.188 Mean :230.7 Mean :146.7 ## 3rd Qu.:22.80 3rd Qu.:8.000 3rd Qu.:326.0 3rd Qu.:180.0 ## Max. :33.90 Max. :8.000 Max. :472.0 Max. :335.0 ## drat wt qsec vs ## Min. :2.760 Min. :1.513 Min. :14.50 Min. :0.0000 ## 1st Qu.:3.080 1st Qu.:2.581 1st Qu.:16.89 1st Qu.:0.0000 ## Median :3.695 Median :3.325 Median :17.71 Median :0.0000 ## Mean :3.597 Mean :3.217 Mean :17.85 Mean :0.4375 ## 3rd Qu.:3.920 3rd Qu.:3.610 3rd Qu.:18.90 3rd Qu.:1.0000 ## Max. :4.930 Max. :5.424 Max. :22.90 Max. :1.0000 ## am gear carb ## Min. :0.0000 Min. :3.000 Min. :1.000 ## 1st Qu.:0.0000 1st Qu.:3.000 1st Qu.:2.000 ## Median :0.0000 Median :4.000 Median :2.000 ## Mean :0.4062 Mean :3.688 Mean :2.812 ## 3rd Qu.:1.0000 3rd Qu.:4.000 3rd Qu.:4.000 ## Max. :1.0000 Max. :5.000 Max. :8.000 Notice that now the summary() function is printing out the summary statistics for each column (aka variable) within our dataframe (mtcars) Now that we’re familiar with our dataset, let’s plot the data to answer our question - what’s the relationship between car weight and miles per gallon? plot(x = mtcars$mpg, y = mtcars$wt, xlab = &quot;Miles per Gallon&quot;, ylab = &quot;Weight (tons)&quot;, main = &quot;Cars Dataset&quot;) Just as we suspected, the lighter the car, the higher the miles per gallon. 5.1.1 Entire Script # load the data - the mtcars dataset is pre-built data(&#39;mtcars&#39;) # print out the first few rows of the dataset using the head() function head(mtcars) # print the class of the mtcars dataset class(mtcars) # dimensions of the mtcars dataframe dim(mtcars) # number of rows nrow(mtcars) # number of columns ncol(mtcars) # column names colnames(mtcars) # row names rownames(mtcars) # selecting the miles per gallon column mtcars[&quot;mpg&quot;] # selecting the vector of the mpg column mtcars$mpg # printing a summary of the dataframe summary(mtcars) # plot weight of cars vs miles per gallon plot(x = mtcars$mpg, y = mtcars$wt, xlab = &quot;Miles per Gallon&quot;, ylab = &quot;Weight (tons)&quot;, main = &quot;Cars Dataset&quot;) 5.1.2 Saving your plot We can save any plot from the R plot window. Simply navigate to the Plots tab and select Export then Save As Image. Figure 5.1: Save As Image "],
["avocados-tutorial-part-1.html", "6 Avocados Tutorial - Part 1 6.1 ggplot2 crash course 6.2 Load the avocados Dataset 6.3 Exploring the Dataset 6.4 Expanding the dataset 6.5 Recap 6.6 Avocado Assignment", " 6 Avocados Tutorial - Part 1 For this tutorial, we’ll pretend we work for a supermarket chain interested in avocado pricing. Understanding price changes and the drivers behind those changes can help us forecast future shifts that enable us to stay ahead of the market and create appropriate pricing given the economic environment. Goals of this tutorial Introduce ggplot2 in more detail Install and Load Packages Load and interact with large dataset Practice ggplot2 plots Datasets used avocado.csv 6.1 ggplot2 crash course ggplot2 is the most popular plotting package in R. It’s regarded as one of the best visualization packages of any open-source programming language and has been refactored to work within other languages such as Python. The advantage of ggplot2 is how optimized it is to work with big data. We can create ggplots for thousands of data points in less than a second. Customization options are also endless with ggplot2. ggplot2 can create the following types of plots: 1) Correlation Scatterplot Scatterplot With Encircling Jitter Plot Counts Chart Bubble Plot Animated Bubble Plot Marginal Histogram / Boxplot Correlogram 2) Deviation Diverging Bars Diverging Lollipop Chart Diverging Dot Plot Area Chart 3) Ranking Ordered Bar Chart Lollipop Chart Dot Plot Slope Chart Dumbbell Plot 4) Distribution Histogram Density Plot Box Plot Dot + Box Plot Tufte Boxplot Violin Plot Population Pyramid 5) Composition Waffle Chart Pie Chart Treemap Bar Chart 6) Change Time Series Plots From a Data Frame Format to Monthly X Axis Format to Yearly X Axis From Long Data Format From Wide Data Format Stacked Area Chart Calendar Heat Map Slope Chart Seasonal Plot 7) Groups Dendrogram Clusters 8) Spatial Open Street Map Google Road Map Google Hybrid Map Additional information on these plots can be found at the following links: * http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html * https://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html * https://ggplot2.tidyverse.org/ All ggplot instances follow the same basic format: first calling ggplot and then a plot type. ggplot takes two arguments: the first is a dataset (a data.frame object) and the second is a call to aes(), where you assign variables in the dataset to components of the graph called aesthetics. The specific type of plot you’d like to make with it is the ggplot2 function for the general type of plot you want: for example, a barplot is called geom_bar as we saw in the last example. Let’s quickly explore these: var1 = seq(from=1, to=30, by=1) var2 = rnorm(n=30, mean = 10, sd = 1) df &lt;- data.frame(x = var1, y = var2) head(df) ## x y ## 1 1 11.154228 ## 2 2 10.590619 ## 3 3 8.527210 ## 4 4 10.644164 ## 5 5 10.343384 ## 6 6 9.558544 Now that we have a data frame with variables var1 and var2, we can create a ggplot. Let’s start by creating the background of our ggplot by using the first calling ggplot. library(ggplot2) ggplot(data = df, aes(x = var1, y = y)) The data argument is declared as our df data.frame. Our x axis and y axis are specified by the var1 and var2 variables within the df dataframe. R understands what var1 and var2 are because it assumes the aesthetics are variables within the data dataframe. Now we can plot a ggplot2 instance using this. ggplot(df, aes(x = var1, y = var2)) + geom_point() ggplot is unique in that it’s components are added via the + sign. So we created the ggplot instance with ggplot(df, aes(x = var1, y = var2)) and added the plotting component with + geom_point(). The geom in geom_point stands for geometry. All geometrical plots in ggplot2 begin with geom. ggplot(df, aes(x = var1, y = var2)) + geom_line() Within the plot type we can specify additional arguments to enhance the plot in a way we’d like. ggplot(df, aes(x = var1, y = var2)) + geom_line(color = &quot;darkblue&quot;, linetype = 2, size = 1) We can also add linear regression lines to our plots easily ggplot(df, aes(x = var1, y = var2)) + geom_smooth(method = &quot;lm&quot;) We can have multiple geometry plots on one ggplot instance… ggplot(df, aes(x = var1, y = var2)) + geom_smooth() + geom_point() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Histograms can be done within 1 line. ggplot(df, aes(x = var2)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Density plots are easy too! ggplot(df, aes(x = var2)) + geom_density() Now that we’ve gone through some example plots with ggplot2, let’s use ggplot2 to plot some real data! 6.2 Load the avocados Dataset First we’ll load in the packages and the avocados dataset. # first let&#39;s load in the packages we need library(data.table) ## data.table 1.12.2 using 2 threads (see ?getDTthreads). Latest news: r-datatable.com library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:data.table&#39;: ## ## between, first, last ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) ## corrplot 0.84 loaded library(leaflet) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:data.table&#39;: ## ## hour, isoweek, mday, minute, month, quarter, second, wday, week, ## yday, year ## The following object is masked from &#39;package:base&#39;: ## ## date # now let&#39;s load in our dataset using read.csv avocado_df &lt;- read.csv(&quot;datasets/avocado.csv&quot;) Let’s check out what the avocados dataframe (avocado_df) looks like. # understand what classes R recognizes our data as class(avocado_df) ## [1] &quot;data.frame&quot; # what about the class of the `type` variable within the avocado_df data frame? class(avocado_df$type) ## [1] &quot;factor&quot; 6.3 Exploring the Dataset Is there null data ? What are various columns ? How many years are in this dataset? How many regions and what are they ? Can we create revenue and profit variables? Is there null data? Null data is a feature of most datasets. In R, null data is classified as NA, or Not Available. If there is null data in a dataset, you’ll see an NA in the dataset. For reference, a blank cell in Microsoft Excel would be regarded as NA when read in R. sum(is.na(avocado_df$AveragePrice) == TRUE) ## [1] 0 To find out if there are any null data points we use the is.na() function. This prints out a logical (aka True or False) for each cell. It prints FALSE if there is data and TRUE if the data is NA. In the code above, we tell R to sum() the number of times the is.na reports TRUE for the AveragePrice variable. We see that the return is 0 here, thus telling us that there are no NA data points in this dataset. ** What are the various column names** With most things in R, there are multiple ways to answer the same question. names(avocado_df) ## [1] &quot;X&quot; &quot;Date&quot; &quot;AveragePrice&quot; &quot;Total.Volume&quot; &quot;X4046&quot; ## [6] &quot;X4225&quot; &quot;X4770&quot; &quot;Total.Bags&quot; &quot;Small.Bags&quot; &quot;Large.Bags&quot; ## [11] &quot;XLarge.Bags&quot; &quot;type&quot; &quot;year&quot; &quot;region&quot; colnames(avocado_df) ## [1] &quot;X&quot; &quot;Date&quot; &quot;AveragePrice&quot; &quot;Total.Volume&quot; &quot;X4046&quot; ## [6] &quot;X4225&quot; &quot;X4770&quot; &quot;Total.Bags&quot; &quot;Small.Bags&quot; &quot;Large.Bags&quot; ## [11] &quot;XLarge.Bags&quot; &quot;type&quot; &quot;year&quot; &quot;region&quot; What years are in this dataset? Use the unique function which returns a list of each character string, number, or whatever is in a vector or list. unique(avocado_df$year) ## [1] 2015 2016 2017 2018 What regions are in this dataset? unique(avocado_df$region) ## [1] Albany Atlanta BaltimoreWashington ## [4] Boise Boston BuffaloRochester ## [7] California Charlotte Chicago ## [10] CincinnatiDayton Columbus DallasFtWorth ## [13] Denver Detroit GrandRapids ## [16] GreatLakes HarrisburgScranton HartfordSpringfield ## [19] Houston Indianapolis Jacksonville ## [22] LasVegas LosAngeles Louisville ## [25] MiamiFtLauderdale Midsouth Nashville ## [28] NewOrleansMobile NewYork Northeast ## [31] NorthernNewEngland Orlando Philadelphia ## [34] PhoenixTucson Pittsburgh Plains ## [37] Portland RaleighGreensboro RichmondNorfolk ## [40] Roanoke Sacramento SanDiego ## [43] SanFrancisco Seattle SouthCarolina ## [46] SouthCentral Southeast Spokane ## [49] StLouis Syracuse Tampa ## [52] TotalUS West WestTexNewMexico ## 54 Levels: Albany Atlanta BaltimoreWashington Boise Boston ... WestTexNewMexico How many regions are in this dataset? length(unique(avocado_df$region)) ## [1] 54 ** What types of avocados are in this dataset ** # Remember, we can query information about a variable using avocado_df$type or avocado_df[&#39;type&#39;] unique(avocado_df[&#39;type&#39;]) ## type ## 1 conventional ## 9127 organic There are 2 types of avocados in this dataset - conventional and organic. Let’s use ggplot2 to plot a density plot of the avocados based on the type. ggplot(avocado_df, aes(x=AveragePrice, fill=type)) + geom_density() Let’s expand this a little further and create 2 geom_density plots within 1 window. ggplot(avocado_df, aes(x=AveragePrice, fill=type)) + geom_density() + facet_wrap(~type) In this plot, we declare our ggplot instance, set the type of plot as a geom_density plot, and then use a facet_wrap to create plots from each type of avocado. This allows you to produce plots subset by variables in your data. If we had additional types of avocados, the facet_wrap function would automatically add those to the plot as well! The ~ is necessary in ~type for facet_wrap to be satisfied. Let’s expand on this plot a little further by adding the following adjustments to theme and labs. theme is the ggplot2 theme you use for your ggplot. labs is the label function. With these two functions, we can declare changes to the x and y labels, title, legend position, etc. ggplot(avocado_df, aes(x=AveragePrice, fill=type)) + geom_density() + facet_wrap(~type) + theme(plot.title=element_text(hjust=0.5), legend.position=&quot;bottom&quot;) + labs(title=&quot;Avocado Price by Type&quot;) Great job! Now let’s save this image to share with our team later on! We can do this by navigating to the Plot window (bottom right quadrant), selecting Export and Save As Image. 6.4 Expanding the dataset Before we expand on this dataset, let’s get rid of unnecessary columns that aren’t useful to us. We do this by declaring the variable equal to NULL avocado_df$X = NULL avocado_df$X4046 = NULL avocado_df$X4225 = NULL avocado_df$X4770 = NULL avocado_df$XLarge.Bags = NULL Calculating Revenue and Profit Revenue = TotalVolume * AveragePrice Profit - Assume that conventional fetches 15% profit of revenue while organic fetchs 45% of revenue Let’s calculate the revenue and add it to our dataframe # we simply multiply the two columns together av_revenue = avocado_df$Total.Volume * avocado_df$AveragePrice # to add our av_revenue vector to the dataframe, add it in like so avocado_df[&#39;revenue&#39;] = av_revenue Now let’s add a blank profit column and populate it based on our conditions above. # add the blank column - remember we can use = or &lt;- for object/variable declaration avocado_df$profit &lt;- NA Now, we need to create 1 profit variable that encompasses 2 conditions. The first is that the conventional avocado has a 15% profit, while the organic avocado has a 45% profit. avocado_df$type[1] ## [1] conventional ## Levels: conventional organic ## use the logical operator to test that avocado_df$type[1] is equal to &#39;conventional&#39; avocado_df$type[1] == &#39;conventional&#39; ## [1] TRUE We see that our test value (row 1 of the avocado_df$type[1]) is conventional and our logical test shows this. Now let’s apply this method above to the profit variable we want to add to the dataset. We’ll do so using the ifelse() function. # let&#39;s use our &quot;is equal to&quot; avocado_df$profit = ifelse(test = avocado_df$type == &#39;conventional&#39;, yes = (avocado_df$revenue * 0.15), no = (avocado_df$revenue * 0.45)) ifelse() takes 3 arguments - test, yes and no. Our test is whether the avocado_df$type is conventional. If it is indeed conventional we multiply our revenue by 0.15 to calculate the profit. Conversely if it is not conventional, then it must be organic and thus we multiply our revenue by 0.45 to calculate the profit. This is the beauty of R in motion. The ifelse() function is automatically rolling through every row and running the same test. Notice how fast this runs. Keep in mind that this dataset is ~18,000 rows long. ** Let’s take a look at our updated dataframe ** It looks great! Let’s save all of our hard work as a new, separate csv file. We do this using the write.csv() function. # x is the dataframe, and the file is the path AND the new filename we want to name our CSV file write.csv(x = avocado_df, file = &quot;/Users/james/Downloads/updated_avocado.csv&quot;) 6.5 Recap ggplot2 is a powerful visualization package ggplot2 takes two objects to create a plot: First, a ggplot instance that creates the x &amp; y axes and second, geom_line or whatever type of plot you want to create. ggplot is unique in that it’s components are added via the + sign Adding and removing columns in our data.frame can be done easily We can save our data.frame to a csv file 6.6 Avocado Assignment Complete the following coding problems and submit the resulting plots and CSV file. HINT: Creating a separate Dataframe of the Albany region is done like so… albany = avocado_df[avocado_df$region == 'Albany',] The profit for California avocados is 5% higher for both conventional and organic avocados. Make an adjustment to the profit variable of the dataframe that reflects the situation where if a rows region is California, the profit is 10% higher for those rows. Save this updated CSV. Create a geom_density() ggplot of the California types of avocados vs. profit. Save this image. Create a new dataframe subselecting the ‘TotalUS’ region. First, plot a geom_point plot of x=Date, y=Total.Volume, and with a facet wrap of the type of avocados. Second, plot a geom_point plot of x=Date, y=profit, and with a facet wrap of the type of avocados. Save these plots. Your final products should look like this… We’ll explore these plots in more detail moving forward - we’ll also clean them up a bit for a nice final product but for now this is great! "],
["avocados-tutorial-part-2.html", "7 Avocados Tutorial - Part 2 7.1 Tidyverse : dplyr crash course 7.2 Avocados Dataframe with dplyr 7.3 Recap 7.4 Avocados 2 Assignment", " 7 Avocados Tutorial - Part 2 We’re going to continue our exploration of the avocados dataset for this tutorial. We’re going to introduce dplyr, an R package with tremendous power that was built with Excel users in mind. Goals of this tutorial * Introduce Tidyverse and dplyr * Practice exploring the avocados dataset using dplyr * Create more advanced ggplot plots * Investigate Avocado price trends Datasets used * avocado.csv 7.1 Tidyverse : dplyr crash course The tidyverse is a collection of R packages for data manipulation, exploration and visualization that share a common design philosophy. The advantages of the tidyverse include consistent functions, workflow coverage, a path to data science education, a parsimonious approach to the development of data science tools, and the possibility of greater productivity. The tidyverse packages can be used in conjunction with any R packages but they are designed to work seamlessly with each other. The basic set of packages are: Figure 7.1: Image courtesy of https://rviews.rstudio.com/2017/06/08/what-is-the-tidyverse/) As we see from the image, we’re already familiar with the visualization package of tidyverse - ggplot2 ! As stated in the introductory material, there are thousands of packages in R, many of which solve the same problem. Tidyverse is just a specific set of packages that are enhanced to work together, so from here on we’re going to stick to this set of R packages for consistency. Tidyverse data science forms what we refer to as tidy datasets, which just refers to specific datasets in tidy format. You can use any R package with tidy datasets and can also use tidyverse packages on a regular data.frame. When you use the set of tidyverse packages together, however, you have some extra functionality which will come in handy. You can read more about tidyverse in this R blog post 7.1.1 Dplyr dplyr is an R package for data manipulation, providing a consistent set of functions that help you solve the most common data manipulation challenges. dplyr is part of the Tidyverse family of packages, thus allowing a user to create tidy datasets. “Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.” (From Wickham, H. (2014): Tidy Data)) select() picks variables based on their names. filter() picks cases based on their values. mutate() adds new variables that are functions of existing variables summarise() reduces multiple values down to a single summary. arrange() changes the ordering of the rows. These all combine naturally with group_by() which allows you to perform any operation by group. 7.1.2 Exploring Dplyr Let’s begin by loading our packages and opening the avocados dataset back up. # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) library(leaflet) library(lubridate) library(cowplot) ## ## ******************************************************** ## Note: As of version 1.0.0, cowplot does not change the ## default ggplot2 theme anymore. To recover the previous ## behavior, execute: ## theme_set(theme_cowplot()) ## ******************************************************** ## ## Attaching package: &#39;cowplot&#39; ## The following object is masked from &#39;package:lubridate&#39;: ## ## stamp # now let&#39;s load in our dataset using read.csv avocado_df &lt;- read.csv(&quot;datasets/avocado.csv&quot;) Now, let’s use dplyr with this dataset. First, let’s select a subset of this dataset using the select() function # subselect the Average Price, Total Volume, and type from our original dataset select_df &lt;- select(.data = avocado_df, AveragePrice, Total.Volume, type) A key thing to notice here is the arguments after the .data argument. If we use the help() function to learn more about select(), we see that the arguments are .data. and .... The ... is another way to describe ambiguous arguments - meaning you can add as many or as few as you want. In this case, we want the variable names we want to select here. Note that even though it’s good practice to always use the convention of argument = my_specific_argument_condition, you don’t have to add the argument = part so long as the arguments are written in the same order the function expects. For example, in the code above, we don’t need to write select(.data = avocado_df, AveragePrice, Total.Volume, type), we can simply write select(avocado_df, AveragePrice, Total.Volume, type). This is true for ALL functions, but you’ll need to keep the order of your arguments straight. Now let’s filter the original avocado_df to extract cases where avocados are organic # filter the dataset when the type is organic filter_df &lt;- filter(.data = avocado_df, type==&#39;organic&#39;) Now let’s mutate the dataset and add our revenue and profit columns. # filter the dataset when the type is organic mutate_df = mutate(avocado_df, revenue = AveragePrice *Total.Volume) 7.1.3 Nested Functions Let’s say we want to create a sub-selected dataset of AveragePrice, Total.Volume, and type where the region is Northeast. nested_df = select(.data = filter(.data = avocado_df, region==&#39;Northeast&#39;), AveragePrice, Total.Volume, type) Notice how our .data is the result of the filter() function where we select only the Northeast region. Here’s what the nested_df looks like now. 7.1.4 Pipes %&gt;% The last option for handling data with dplyr, pipes, are a fairly recent addition to R. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. You’ll see more advanced code make use of this. We’ll show a quick example here so you can see how it works, but we won’t use it for the rest of the tutorial after this. Let’s do the exact same thing above only this time let’s use pipes. pipe_df &lt;- avocado_df %&gt;% filter(region==&#39;Northeast&#39;) %&gt;% select(AveragePrice, Total.Volume, type) Above code reads like so to create the pipe_df dataframe. Begin with avocado_df and send that to the filter() function where we grab the Northeast region from the avocado_df dataset, then immediately send the result of the filter to the select function where we sub-select the AveragePrice, Total.Volume, type variables. As we’ll see, the output is the same - it’s just another way of coding! 7.2 Avocados Dataframe with dplyr In this tutorial we’re going to accomplish the following: Plot Price Trends over time for both types of avocados 7.2.1 Price Trends First, let’s check out our date column. # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(tibbletime) ## Warning: package &#39;tibbletime&#39; was built under R version 3.6.2 ## ## Attaching package: &#39;tibbletime&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter # now let&#39;s load in our dataset using read.csv avocado_df &lt;- read.csv(&quot;datasets/avocado.csv&quot;) class(avocado_df$Date) ## [1] &quot;factor&quot; We need to change the class of the avocado_df$Date column. We can do this using as.Date function that can reclassify a variable as a date class in R. We know that the date is stored as Year-Month-Day, so we relay this to R which uses the following format for classifying datestrings &quot;%Y-%m-%d&quot; . %Y is a 4 digit year, %m is a 2 digit month, and %d is a 2 digit day. More can be read on this here. # Change the date column from factor to date avocado_df$Date &lt;- as.Date(avocado_df$Date, &quot;%Y-%m-%d&quot;) class(avocado_df$Date) ## [1] &quot;Date&quot; Now let’s sort the dates via the order function so we can analyze the price trends over time. # Sort the dates avocado_df &lt;- avocado_df[order(avocado_df$Date),] head(avocado_df$Date) ## [1] &quot;2015-01-04&quot; &quot;2015-01-04&quot; &quot;2015-01-04&quot; &quot;2015-01-04&quot; &quot;2015-01-04&quot; ## [6] &quot;2015-01-04&quot; Now let’s select the columns we want using dplyr and plot them using ggplot price_trend &lt;- select(.data = avocado_df, Date, AveragePrice, type) ggplot(data = price_trend, aes(x = Date, y = AveragePrice, col=type)) + geom_line() + facet_wrap(~type) + theme(legend.position=&quot;bottom&quot;) Notice that we had the following arguments in the aes parameter - x, y, col. Our x axis is the date, y axis is the AveragePrice, and we color the data based on the type of avocado. Can we spice this plot up a bit by customizing the colors? Sure! Altering the colors of the plots using scale_color_manual # Create a Facet Wrap for each product ggplot(data = price_trend, aes(x = Date, y = AveragePrice, col=type)) + geom_line() + facet_wrap(~ type) + theme_minimal() + theme(legend.position=&quot;bottom&quot;) + scale_color_manual(values=c(&quot;blue&quot;, &quot;green&quot;)) # Create a Facet Wrap for each product ggplot(data = price_trend, aes(x = Date, y = AveragePrice, col=type)) + geom_line() + facet_wrap(~ type) + theme_minimal() + theme(legend.position=&quot;bottom&quot;) + scale_color_manual(values=c(&quot;dodgerblue4&quot;, &quot;darkgreen&quot;)) We used the function scale_color_manual because we defined the coloring via the col argument in the aes function. Had we chosen another function that requires a fill instead of a col, we would have had to use scale_fill_manual. Notice that the argument for the scale_color_manual is values=, which takes a list that must be the same length as the input parameters. R has a wide range of colors to choose from - a list can be found here. we see that the average price of organic avocados is higher than conventional avocados. 7.2.2 Price and Total Volume Supply and demand is key component of pricing. Let’s examine the relationship between the price and total volume. We begin by creating separate dataframes for organic and conventional. # Filter by type - our input data for selected variabls is teh filtered organic/conventional data organic &lt;- select(.data = filter(.data = avocado_df,type == &quot;organic&quot;), Date, AveragePrice, type, Total.Volume) conventional &lt;- select(.data = filter(.data = avocado_df,type == &quot;conventional&quot;), Date, AveragePrice, type, Total.Volume) We’ve created our two new datasets. Let’s say we want to average the data by month to make it easier to work with and analyze. This is easy once we convert our data.frame to a tibbletime tbl_df. tibbletime is a separate tibble package that obeys the nomenclature associated with the greater R Tidyverse. tibbletime is an advanced R package that is great when working with dataframes. It also allows us to convert our standard R data.frame to a tibbletime data.frame. This allows us to do fancy things with the dataframe like average the data by each month of the datetime. # organize the organic dataframe as a tbl_time object where the index is the Date organic &lt;- as_tbl_time(organic, index=Date) class(organic) ## [1] &quot;tbl_time&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; We can use the as_period function to average this data into a monthly dataset. organic &lt;- as_period(organic, &#39;1 month&#39;) Let’s do the same for conventional avocados # Conventional Avocadoes conventional &lt;- as_tbl_time(conventional, index=Date) conventional &lt;- as_period(conventional, &#39;1 month&#39;) Now let’s plot up the the price trends with the volume trends of both types of avocados. We’ll be creating a total of 4 plots and we’ll want them in the same window. In order to achieve this, we will use a package called cowplot which has a function called plot_grid. plot_grid allows us to plot any number of ggplot instances in the same window. # Let&#39;s create a conventional average price chart conventional_price &lt;- ggplot(data = conventional, aes(x=Date, y=AveragePrice)) + geom_line(color=&quot;dodgerblue2&quot;) + labs(title=&quot;Conventional Avocados&quot;) + geom_hline(yintercept=max(conventional$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept=min(conventional$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;blue&quot;) # Let&#39;s create a conventional volume chart conventional_volume &lt;- ggplot(data = conventional, aes(x=Date, y=Total.Volume)) + geom_bar(stat=&#39;identity&#39;, fill=&quot;dodgerblue2&quot;, color=&quot;black&quot;) + geom_smooth(method=&quot;loess&quot;, color=&quot;red&quot;) # Let&#39;s create an organic average price chart organic_price = ggplot(data = organic, aes(x=Date, y=AveragePrice)) + geom_line(color=&quot;darkgreen&quot;) + labs(title=&quot;Organic Avocados&quot;) + geom_hline(yintercept=max(organic$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept=min(organic$AveragePrice), linetype=&quot;dashed&quot;, color = &quot;blue&quot;) # Let&#39;s create a organic volume chart organic_volume &lt;- ggplot(data = organic, aes(x=Date, y=Total.Volume)) + geom_bar(stat=&#39;identity&#39;, fill=&quot;darkgreen&quot;,color=&quot;black&quot;) + geom_smooth(method=&quot;loess&quot;, color=&quot;yellow&quot;) #now use cowplot plot_grid to plot all 4 plots in the same window plot_grid(conventional_price, organic_price,conventional_volume, organic_volume, nrow=2, ncol=2) Notice that we created 4 separate ggplots and saved them as objects. Once we had all of the objects created, we placed them in plot_grid as the plots we wanted to add to the plot_grid window. Then we specified the number of rows and columns we wanted the grid to have via nrow and ncol, respectively. Summary: 2015 prices were in the $1.00 range for conventional avocados. In 2016 and 2017, the density of the prices were a little bit higher. It looks that most price peaks occur for both conventional and organic avocados between the months of September and October. I wonder why this is? Could it have to do with fall sport viewing which is often accompanied by guacamole? Major price drop at the end of each year. Why is demand dropping so much? 7.2.3 Yearly and Monthly Patterns We have 4 years of data in this dataset, so we have 4 values for each month when it comes to Average Price. Let’s reorganize our data to include a month variable and then average the 4 values for each month together to create a monthly price point average. # create a separate dataframe by first copying the original avocado_df seasonal_df &lt;- avocado_df # create 3 new variables, just expanding on the date using the format function # let&#39;s test out the format function to see what it does avocado_df$Date[1] ## [1] &quot;2015-01-04&quot; format(as.Date(avocado_df$Date[1]), &quot;%Y-%m&quot;) ## [1] &quot;2015-01&quot; # create the variables - notice the structure of the format seasonal_df$year_month &lt;- format(avocado_df$Date, &quot;%Y-%m&quot;) seasonal_df$month &lt;- format(avocado_df$Date, &quot;%m&quot;) seasonal_df$year &lt;- format(avocado_df$Date, &quot;%Y&quot;) # print out the first 10 values seasonal_df$month[1:10] ## [1] &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; &quot;01&quot; Let’s take this one step further and let’s convert our month variable to an Abbreviated Month (aka month “01”&quot; is Jan). We can do this by using the month.abb function (which requires the input to be a numeric, so we convert the seasonal_df$month to numeric within the funciton) seasonal_df$monthchr &lt;- month.abb[as.numeric(seasonal_df$month)] seasonal_df$monthchr[1:10] ## [1] &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; &quot;Jan&quot; class(seasonal_df$monthchr) ## [1] &quot;character&quot; This is a character, so let’s change this to a factor where the levels available are R’s abbreviated months - aka month.abb seasonal_df$monthabb = factor(seasonal_df$monthchr, levels = month.abb) seasonal_df$monthabb[1:10] ## [1] Jan Jan Jan Jan Jan Jan Jan Jan Jan Jan ## Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Our dataset is now organized - let’s plot it up to learn more about the avocados! First let’s plot a density plot of the distribution of prices by year. ** Distribution of Average Prices by year for both avocado types ** ggplot(seasonal_df, aes(x = AveragePrice, fill = year)) + geom_density(alpha = .5) + facet_wrap(~year) + labs(title=&quot;Distribution of Prices by year&quot;, x = &#39;Average Price&#39;, y = &#39;Density&#39;) + scale_fill_manual(values=c(&quot;blue&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;red&quot;)) Notice that we used the scale_fill_manual argument here because the geom_density argument requires a fill value in the ggplot components aes function. ** Distribution of Average Prices by month for the Conventional Avocado ** Let’s select the conventional avocados using select and filter from dplyr. conventional = select(.data = filter(.data = seasonal_df,type == &#39;conventional&#39;), monthabb, AveragePrice, type) Now, let’s group this dataframe by the monthabb variable month_df = group_by(.data = conventional, monthabb) Now, we can summzarize this data by taking the mean() of the AveragePrice variable and creating a new variable named avg month_df = summarize(.data = month_df, avg=mean(AveragePrice)) Plot the price distrubion by month! ggplot(data = month_df, aes(x=monthabb, y=avg)) + geom_point(color=&quot;red&quot;, aes(size=avg)) + geom_line(group=1, color=&quot;blue&quot;) + labs(title=&quot;Conventional Avocados&quot;, x=&quot;Month&quot;, y=&quot;Average Price&quot;) Summary: - October is the best month for Conventional Avocados for the entire dataset with average prices above $1.30 - February is the worst month for Conventional Avocados with average prices barely above $1.00 7.3 Recap Tidyverse is a set of R packages designed with consistent framework and usability - dplyr and tibbletime are very useful when dealing with spreadsheet data Subselecting, grouping, averaging can all be accomplished with dplyr and tibbletime plot_grid from the cowplot package is useful for plotting multiple ggplot2 plots in the same window ggplot2 plots are extremely customizable - we used scale_color_manual as one example of how customizable they are here. 7.4 Avocados 2 Assignment Perform the same analysis onthe price distribution by month that we did for Conventional Avocados only this time explor the Organic type of avocados. Combine both plots to be part of the same window. Use custom colors selected from the R color guide. Create proper labels with ggplot2s lab() function. Submit final plot. Your final plot should look something like this… "],
["us-work-visas-part-1.html", "8 US Work Visas - Part 1 8.1 The For Loop - Quick Introduction 8.2 paste() and paste0() - Quick Introduction 8.3 Exploring the Data 8.4 Recap 8.5 Visa 1 Assignment", " 8 US Work Visas - Part 1 In this tutorial, we’ll be exploring the H1-B Visa. The H-1B is a visa in the United States which allows U.S. employers to employ foreign workers in specialty occupations. We’ll examine what kind of foreign workers are most often employed. Goals of this tutorial Introduce the for loop and paste0 Use R to load in big data Practice using dplyr and tibble on the visa dataset Investigate H1-B visa trends Datasets used h1bvisa_part1.csv h1bvisa_part2.csv h1bvisa_part3.csv h1bvisa_part4.csv h1bvisa_part5.csv h1bvisa_part6.csv h1bvisa_part7.csv 8.1 The For Loop - Quick Introduction For loops &amp; conditional statements are a key skill in programming. They allow you to process through large datasets or multiple datasets thus minimizing the amount of manual work you need to do. The basic for loop looks like this… # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result for (i in numbersList){ temNumber = i * 8 print(temNumber) } ## [1] 8 ## [1] 16 ## [1] 24 ## [1] 32 ## [1] 40 ## [1] 48 ## [1] 56 ## [1] 64 ## [1] 72 ## [1] 80 Notice the general structure of R for loops. ‘for’ signals to R you’re beginning a for loop, which requires the general structure to look like: for (numbers/values to loop through){ condition for the looping using the numbers/values above } Yes, you must have these parentheses and curly brackets present and surrounding the appropriate code. If you forget a parentheses or curly bracket you’ll have errors pop up…this happens to me all the time still. While these must be present, R doesn’t care where they are in your code (****which is very unique amongst programming languages). For example, notice how this ugly code is different but still runs… # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result for ( i in numbersList ){ temNumber = i * 8 print(temNumber) } ## [1] 8 ## [1] 16 ## [1] 24 ## [1] 32 ## [1] 40 ## [1] 48 ## [1] 56 ## [1] 64 ## [1] 72 ## [1] 80 The general structure is still: for(condition){do something}. If statements are set up the same way # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result for (i in numbersList){ if (i==4){ temNumber = i * 8 print(temNumber) } } ## [1] 32 This is referred to as a ‘nested loop’, because there is a conditional statement within another one. Key takeaway here: in programming languages, ‘=’ is an assignment (i.e. x = 4), whereas ‘==’ is an equality test (i == 4). To put this loop in layman’s terms: for i in numbersList, if i is equal to 4, multiply i by 8 and then print temNumber. We can also have nested for loops. # Generate sequence of numbers from 1 to 3 this time using the seq() function (seq for sequence) numbersList = seq(from=1,to=3,by=1) lettersList = list(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) for (num in numbersList){ for (let in lettersList){ print(c(num,let)) } } ## [1] &quot;1&quot; &quot;A&quot; ## [1] &quot;1&quot; &quot;B&quot; ## [1] &quot;1&quot; &quot;C&quot; ## [1] &quot;2&quot; &quot;A&quot; ## [1] &quot;2&quot; &quot;B&quot; ## [1] &quot;2&quot; &quot;C&quot; ## [1] &quot;3&quot; &quot;A&quot; ## [1] &quot;3&quot; &quot;B&quot; ## [1] &quot;3&quot; &quot;C&quot; You can name the object within the list whatever you want (i, j, num, let, etc.). Reminder, c() is the concatenate functin that combines values into a vector or list. The order doesn’t matter in this for loop… # Generate sequence of numbers from 1 to 3 this time using the seq() function (seq for sequence) numbersList = seq(from=1,to=3,by=1) lettersList = list(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) for (let in lettersList){ for (num in numbersList){ print(c(num,let)) } } ## [1] &quot;1&quot; &quot;A&quot; ## [1] &quot;2&quot; &quot;A&quot; ## [1] &quot;3&quot; &quot;A&quot; ## [1] &quot;1&quot; &quot;B&quot; ## [1] &quot;2&quot; &quot;B&quot; ## [1] &quot;3&quot; &quot;B&quot; ## [1] &quot;1&quot; &quot;C&quot; ## [1] &quot;2&quot; &quot;C&quot; ## [1] &quot;3&quot; &quot;C&quot; But it does in this one… # Generate sequence of numbers from 1 to 10 using the seq() function (seq for sequence) numbersList = seq(from=1,to=10,by=1) # Multiply each number in the numbersList by 8 and print the result if (i==4){ for (i in numbersList){ temNumber = i * 8 print(temNumber) } } Here’s one more example for multi conditional statement with an else… # Generate sequence of numbers from 1 to 3 this time using the seq() function (seq for sequence) numbersList = seq(from=1,to=3,by=1) lettersList = list(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) for (num in numbersList){ for (let in lettersList){ if (num == 3 &amp;&amp; let == &quot;B&quot;){ print(c(num,let)) } else{ print(&quot;Not what we want&quot;) } } } ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;Not what we want&quot; ## [1] &quot;3&quot; &quot;B&quot; ## [1] &quot;Not what we want&quot; &amp;&amp; means “and” … || means “or”…these are useful in multi conditional statements. The ‘else’ statement is an appendage of the ‘if’ statement. It basically means if num == 3 and let == B is false, print “not what we want”. Notice that the ‘else’ statement is outside of the ‘if’ statement but immediately after it. 8.2 paste() and paste0() - Quick Introduction paste() paste0() are some of the most commonly used functions in R. These allow you concatenate a series of strings together into 1. This is very handy when it comes ot writing filepaths to read/write data files. # Paste Example 1 - default sep (aka separation) is space paste(&quot;file&quot;, &quot;number&quot;, &quot;32&quot;) ## [1] &quot;file number 32&quot; # Paste Example 2 - set sep to &quot;_&quot; paste(&quot;file&quot;, &quot;number&quot;, &quot;32&quot;, sep = &quot;_&quot;) ## [1] &quot;file_number_32&quot; # Paste0 Example 1 - 0 for 0 separating characters paste0(&quot;file&quot;, &quot;number&quot;, &quot;32&quot;) ## [1] &quot;filenumber32&quot; # Notice that paste() is limiting because the separating character is not always present between # each string you&#39;re concatenating # Let&#39;s use paste0 here fileList &lt;- c(&#39;filename1&#39;, &#39;filename2&#39;, &#39;filename3&#39;, &#39;filename4&#39;) dateFolder &lt;- c(&#39;0813&#39;, &#39;0814&#39;, &#39;0815&#39;, &#39;0816&#39;) homeDir &lt;- &quot;~/Documents/&quot; pathList &lt;- list() for (i in 1:length(fileList)){ print(i) tempString &lt;- paste0(homeDir, dateFolder[i], &#39;/&#39;, fileList[i]) pathList[i] &lt;- tempString } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 pathList ## [[1]] ## [1] &quot;~/Documents/0813/filename1&quot; ## ## [[2]] ## [1] &quot;~/Documents/0814/filename2&quot; ## ## [[3]] ## [1] &quot;~/Documents/0815/filename3&quot; ## ## [[4]] ## [1] &quot;~/Documents/0816/filename4&quot; pathList[[1]] ## [1] &quot;~/Documents/0813/filename1&quot; 8.3 Exploring the Data 8.3.1 Reading in multiple datasets and combining them # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) library(leaflet) library(lubridate) library(cowplot) For this tutorial, we have 7 separate CSV files. Let’s show a few different ways to load all 7 and merge them together into a single data.frame instance. The first way we’ll show loading in multiple datasets is the for loop! # define our path path = &quot;datasets/visa_data/&quot; # first, create a sequence of numbers 1:7 nseq = seq(1,7) csv_list = list() # create a list of all the filenames for (n in nseq){ csv_list[n] = paste0(&#39;h1bvisa_part&#39;, n, &#39;.csv&#39;) } # now using that list above, let&#39;s read in all files and then append them to the original dataframe for (c in 1:length(csv_list)){ if (c == 1){ visa_df = read.csv(paste0(path, csv_list[c])) } else { nextPart = read.csv(paste0(path, csv_list[c])) visa_df = rbind(visa_df, nextPart) } } # check out the class class(visa_df) ## [1] &quot;data.frame&quot; # check out the dimensions dim(visa_df) ## [1] 647809 12 # check out the dimensions if our `nextPart` that&#39;s being overwritten dim(nextPart) ## [1] 47804 12 Let’s break down this code. First we declare our list of CSV names and the Path that they’re located at. Then, we begin the for loop. We state that for c in 1 to the length of the csv_list (i.e. - 1 to 3), do what’s in the loop. Inside the loop, our first clause states that if c==1 we want to create a data.frame called visa_df. We use our read.csv() function and direct that function to the path and filename of our csv. If it’s the 2nd or 3rd iteration of the loop, the visa_df is already created and thus we want to append our additional data to this data.frame. We do this by loading in the CSV files to our temporary nextPart variable. Once nextPart is loaded, we then use the rbind() function which stands for row bind. We bind together the two dataframes (visa_df and nextPart) by their rows. In other words, we just add in the additional data as additional rows since the datasets share the same column names. The end product is our single dataframe that we created from 3 separate csv files. ## Warning in instance$preRenderHook(instance): It seems your data is too big ## for client-side DataTables. You may consider server-side processing: https:// ## rstudio.github.io/DT/server.html As with many things in R, there are multiple ways to achieve the same goal. Here’s a more advanced (yet simpler) way to read in and merge these files. library(dplyr) library(readr) # set the path csv_path = &quot;datasets/visa_data/&quot; # list all files within that path csv_list = list.files(path=csv_path, full.names = TRUE) csv_list ## [1] &quot;datasets/visa_data//h1bvisa_part1.csv&quot; ## [2] &quot;datasets/visa_data//h1bvisa_part2.csv&quot; ## [3] &quot;datasets/visa_data//h1bvisa_part3.csv&quot; ## [4] &quot;datasets/visa_data//h1bvisa_part4.csv&quot; ## [5] &quot;datasets/visa_data//h1bvisa_part5.csv&quot; ## [6] &quot;datasets/visa_data//h1bvisa_part6.csv&quot; ## [7] &quot;datasets/visa_data//h1bvisa_part7.csv&quot; # Read all csv files in the folder and create a list of dataframes ldf &lt;- lapply(csv_list , read.csv) # Combine each dataframe in the list into a single dataframe visa_df &lt;- do.call(&quot;rbind&quot;, ldf) In this more advanced example, we load in the packages that contain the following functions (this is already done above, but I’m doing it again to show you where these functions come from). After setting the csv_path, we then use the function list.files() which lists all files within a give path. In our case, all of our Visa CSV data is located within /datasets/visa_data. Then we use the lapply function which is a function useful for performing operations on list objects and returns a list object of same length of original set. We give lapply a list (csv_list) and a function (read.csv) to do on that list. This creates a larger list of the output of read_csv from our csv_list. Finally, we create our visa_df via the do.call function (which behaves very similar to lapply). The do.call function is given a function (rbind) and then a list to perform that function on (ldf). lapply and do.call are similar but here’s the difference: lapply() applies a given function for each element in a list,so there will be several function calls. do.call() applies a given function to the list as a whole,so there is only one function call. Once again, here’s our visa_df ## Warning in instance$preRenderHook(instance): It seems your data is too big ## for client-side DataTables. You may consider server-side processing: https:// ## rstudio.github.io/DT/server.html Now that we have our dataset, let’s explore it! 8.3.2 Manipulating our Data Frame X1,X2,X - not named column, it is the id of the row; CASE_STATUS - status of the application; EMPLOYER_NAME - the name of the employer as registered in the H-1B Visa application; SOC_NAME - the occupation code for the employment; JOB_TITLE - the job title for the employment; FULL_TIME_POSITION - whether the application is for a full-time position of for a part-time position; PREVAILING_WAGE - the most frequent wage for the corresponding role as filled in the Visa application; YEAR - the application year; WORKSITE - the address of the employer worksite; lon - longitude of the employer worksite; lat - latitude of the employer worksite; First, let’s get rid of columns we don’t need like X.2, X.1, and X. visa_df$X.2 = NULL visa_df$X.1 = NULL visa_df$X = NULL Next, we notice that the WORKSITE variable contains a City, State type string. Let’s break this out and create a new column with just states. library(stringr) # str_split or string split is a great function to use. It breaks up a string based on a character. In this case we want to split our string into a list of cities and states which are split by a comma worksites = str_split(visa_df$WORKSITE, &quot;,&quot;, simplify = TRUE) head(worksites) ## [,1] [,2] ## [1,] &quot;ANN ARBOR&quot; &quot; MICHIGAN&quot; ## [2,] &quot;PLANO&quot; &quot; TEXAS&quot; ## [3,] &quot;JERSEY CITY&quot; &quot; NEW JERSEY&quot; ## [4,] &quot;DENVER&quot; &quot; COLORADO&quot; ## [5,] &quot;ST. LOUIS&quot; &quot; MISSOURI&quot; ## [6,] &quot;MIAMI&quot; &quot; FLORIDA&quot; # grab the second column which is just the states states = worksites[,2] head(states) ## [1] &quot; MICHIGAN&quot; &quot; TEXAS&quot; &quot; NEW JERSEY&quot; &quot; COLORADO&quot; &quot; MISSOURI&quot; ## [6] &quot; FLORIDA&quot; # Now we can use the trimws() function to trim the whitespace and get rid of the leading spaces states = trimws(states) head(states) ## [1] &quot;MICHIGAN&quot; &quot;TEXAS&quot; &quot;NEW JERSEY&quot; &quot;COLORADO&quot; &quot;MISSOURI&quot; ## [6] &quot;FLORIDA&quot; # now add it to the dataframe visa_df$states &lt;- states Next we notice that our Latitudes and Longitude columns are very specific, let’s round these to make them easier on the eye. visa_df$lat = round(visa_df$lat,3) visa_df$lon = round(visa_df$lon,3) 8.3.3 Case Status Investigation One of the key metrics of this dataset is the Case Status. Let’s filter out the NA values in the dataset and plot this up. # use the filter function from dplyr to filter the visa_df for all cases where CASE_STATUS is NOT NA (!is.na) case_df = filter(.data = visa_df, !is.na(CASE_STATUS)) head(case_df) ## CASE_STATUS ## 1 CERTIFIED-WITHDRAWN ## 2 CERTIFIED-WITHDRAWN ## 3 CERTIFIED-WITHDRAWN ## 4 CERTIFIED-WITHDRAWN ## 5 WITHDRAWN ## 6 CERTIFIED-WITHDRAWN ## EMPLOYER_NAME ## 1 UNIVERSITY OF MICHIGAN ## 2 GOODMAN NETWORKS, INC. ## 3 PORTS AMERICA GROUP, INC. ## 4 GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY OF TOMKINS PLC ## 5 PEABODY INVESTMENTS CORP. ## 6 BURGER KING CORPORATION ## SOC_NAME ## 1 BIOCHEMISTS AND BIOPHYSICISTS ## 2 CHIEF EXECUTIVES ## 3 CHIEF EXECUTIVES ## 4 CHIEF EXECUTIVES ## 5 CHIEF EXECUTIVES ## 6 CHIEF EXECUTIVES ## JOB_TITLE ## 1 POSTDOCTORAL RESEARCH FELLOW ## 2 CHIEF OPERATING OFFICER ## 3 CHIEF PROCESS OFFICER ## 4 REGIONAL PRESIDEN, AMERICAS ## 5 PRESIDENT MONGOLIA AND INDIA ## 6 EXECUTIVE V P, GLOBAL DEVELOPMENT AND PRESIDENT, LATIN AMERI ## FULL_TIME_POSITION PREVAILING_WAGE YEAR WORKSITE lon ## 1 N 36067.0 2016 ANN ARBOR, MICHIGAN -83.743 ## 2 Y 242674.0 2016 PLANO, TEXAS -96.699 ## 3 Y 193066.0 2016 JERSEY CITY, NEW JERSEY -74.078 ## 4 Y 220314.0 2016 DENVER, COLORADO -104.990 ## 5 Y 157518.4 2016 ST. LOUIS, MISSOURI -90.199 ## 6 Y 225000.0 2016 MIAMI, FLORIDA -80.192 ## lat states ## 1 42.281 MICHIGAN ## 2 33.020 TEXAS ## 3 40.728 NEW JERSEY ## 4 39.739 COLORADO ## 5 38.627 MISSOURI ## 6 25.762 FLORIDA # Now let&#39;s group the data by Case_status case_df = group_by(.data = case_df, CASE_STATUS) head(case_df) ## # A tibble: 6 x 11 ## # Groups: CASE_STATUS [2] ## CASE_STATUS ## &lt;fct&gt; ## 1 CERTIFIED-WITHDRAWN ## 2 CERTIFIED-WITHDRAWN ## 3 CERTIFIED-WITHDRAWN ## 4 CERTIFIED-WITHDRAWN ## 5 WITHDRAWN ## 6 CERTIFIED-WITHDRAWN ## EMPLOYER_NAME ## &lt;fct&gt; ## 1 UNIVERSITY OF MICHIGAN ## 2 GOODMAN NETWORKS, INC. ## 3 PORTS AMERICA GROUP, INC. ## 4 GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY OF TOMKINS PLC ## 5 PEABODY INVESTMENTS CORP. ## 6 BURGER KING CORPORATION ## SOC_NAME ## &lt;fct&gt; ## 1 BIOCHEMISTS AND BIOPHYSICISTS ## 2 CHIEF EXECUTIVES ## 3 CHIEF EXECUTIVES ## 4 CHIEF EXECUTIVES ## 5 CHIEF EXECUTIVES ## 6 CHIEF EXECUTIVES ## JOB_TITLE ## &lt;fct&gt; ## 1 POSTDOCTORAL RESEARCH FELLOW ## 2 CHIEF OPERATING OFFICER ## 3 CHIEF PROCESS OFFICER ## 4 REGIONAL PRESIDEN, AMERICAS ## 5 PRESIDENT MONGOLIA AND INDIA ## 6 EXECUTIVE V P, GLOBAL DEVELOPMENT AND PRESIDENT, LATIN AMERI ## FULL_TIME_POSITION PREVAILING_WAGE YEAR WORKSITE lon lat ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 N 36067 2016 ANN ARBOR, MICHIGAN -83.7 42.3 ## 2 Y 242674 2016 PLANO, TEXAS -96.7 33.0 ## 3 Y 193066 2016 JERSEY CITY, NEW JERSEY -74.1 40.7 ## 4 Y 220314 2016 DENVER, COLORADO -105. 39.7 ## 5 Y 157518. 2016 ST. LOUIS, MISSOURI -90.2 38.6 ## 6 Y 225000 2016 MIAMI, FLORIDA -80.2 25.8 ## states ## &lt;chr&gt; ## 1 MICHIGAN ## 2 TEXAS ## 3 NEW JERSEY ## 4 COLORADO ## 5 MISSOURI ## 6 FLORIDA # Now let&#39;s summarize the data based on total number of cases which would be the length of any variable within each sub-group. Here we choose the `lat` variable but it could be any variable here case_df = summarise(.data = case_df, total_cases = length(lat)) head(case_df) ## # A tibble: 4 x 2 ## CASE_STATUS total_cases ## &lt;fct&gt; &lt;int&gt; ## 1 CERTIFIED 569650 ## 2 CERTIFIED-WITHDRAWN 47094 ## 3 DENIED 9175 ## 4 WITHDRAWN 21890 # plot it up! ggplot(data = case_df, aes(x = reorder(CASE_STATUS,total_cases), y = total_cases/1000)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;coral&quot;, colour=&quot;dodgerblue4&quot;) + labs(title=&quot;H1-B Visa Applications&quot;, x =&quot;Case Status&quot;, y = &quot;Number of applications (thousands)&quot;) Something to notice with this ggplot instance is the aes edits for x and y arguments. Notice that we reorder the CASE_STATUS based on the total_cases metric. Also see that we divide teh total_cases by 1000 in order to make the graph more general. Over 100,000 cases are Certified. Less than 5,000 cases are denied. 8.3.4 Job Titles What’s the most common type of job for these visa requests? To find out, we’ll have to look at the JOB_TITLE variable. Let’s organize the data based on this variable # group the data based on the JOB_TITLE variable job_df = group_by(.data = visa_df, JOB_TITLE) ## Warning: Factor `JOB_TITLE` contains implicit NA, consider using ## `forcats::fct_explicit_na` # summarize the data based on the total number of each JOB TITLE, here we aggregate the total number of latitude values for each JOB TITLE job_df = summarise(.data = job_df, total_records = length(lat)) # trim our dataset down so that we only keep the top 50 JOB_TITLE values job_df = top_n(x= job_df, n=50) ## Selecting by total_records # arrange the data based on the total number of records (before this it was organized alphabetically) job_df = arrange(.data = job_df, -total_records) # print out the head of job_df head(job_df) ## # A tibble: 6 x 2 ## JOB_TITLE total_records ## &lt;fct&gt; &lt;int&gt; ## 1 PROGRAMMER ANALYST 53745 ## 2 SOFTWARE ENGINEER 30669 ## 3 SOFTWARE DEVELOPER 14042 ## 4 SYSTEMS ANALYST 12314 ## 5 COMPUTER PROGRAMMER 11668 ## 6 BUSINESS ANALYST 9167 Now, let’s use ggplot2 to show us what the most popular job titles these visa’s had. ggplot(data = job_df, aes(x = JOB_TITLE, y = total_records)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;aquamarine3&quot;, colour=&quot;black&quot;) + labs(title=&quot;&quot;, x =&quot;Job title (top 50)&quot;, y = &quot;Number of applications&quot;) Hmm…that doesn’t look great. What if we want to swap the X and Y axis? Simple! we just add in a coord_flip() ggplot(data = job_df, aes(x = JOB_TITLE, y = total_records)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;aquamarine3&quot;, colour=&quot;black&quot;) + coord_flip() + labs(title=&quot;&quot;, x =&quot;Job title (top 50)&quot;, y = &quot;Number of applications&quot;) Looks better, but how about we reorder it all based on the total_records column. Just use the reorder function! ggplot(data = job_df, aes(x = reorder(JOB_TITLE,total_records), y = total_records)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;aquamarine3&quot;, colour=&quot;black&quot;) + coord_flip() + labs(title=&quot;2016 H1-B Visa Applications&quot;, x =&quot;Job title (top 50)&quot;, y = &quot;Number of applications&quot;) The most frequent titles are BUSINESS ANALYST, PROGRAMMER ANALYST, and SYSTEMS ANALYST. 8.4 Recap For loops are a popular coding practice and can be very useful. In R, for loops are designed to look like for (numbers or values to loop over){ condition where numbers/values is looping } paste0() is great for combining character strings and numbers together R is great for big data (visa_df is ultimately 647,000 rows of data) dplyr and tibble are once again great R packages for handling big data 8.5 Visa 1 Assignment List the top 10 states who apply for this H1-B Visa Application. In the last example above, we examined the JOB_TITLE variable and discovered the most popular jobs. For this assignment, examine the most popular employers. In other words, create a ggplot instance of the top 50 repeat employers who apply for the H1-B Visa. Try and make it similar to the plot below ## Selecting by total_records "],
["us-work-visas-part-2.html", "9 US Work Visas - Part 2 9.1 Revisiting the H1-B Visa Dataset 9.2 Full Time Positions 9.3 Applications by State 9.4 Prevailing Wage by Location 9.5 Recap 9.6 Assignment", " 9 US Work Visas - Part 2 In this tutorial, we’ll be exploring the H1-B Visa. The H-1B is a visa in the United States which allows U.S. employers to employ foreign workers in specialty occupations. We’ll examine what kind of foreign workers are most often employed. Goals of this tutorial Introduce advanced plotting routines Further explore the H1-B visa dataset Focus on spatial distribution of applications Practice dplyr and tibble Datasets used h1bvisa_part1.csv h1bvisa_part2.csv h1bvisa_part3.csv h1bvisa_part4.csv h1bvisa_part5.csv h1bvisa_part6.csv h1bvisa_part7.csv 9.1 Revisiting the H1-B Visa Dataset We’re already familiar with this dataset from last week, so let’s dive right in from where we left off. # first let&#39;s load in the packages we need library(data.table) library(dplyr) library(ggplot2) library(stringr) library(DT) library(tidyr) library(corrplot) library(leaflet) library(lubridate) library(cowplot) library(dplyr) library(readr) library(stringr) # set the path csv_path = &quot;datasets/visa_data/&quot; # list all files within that path csv_list = list.files(path=csv_path, full.names = TRUE) csv_list ## [1] &quot;datasets/visa_data//h1bvisa_part1.csv&quot; ## [2] &quot;datasets/visa_data//h1bvisa_part2.csv&quot; ## [3] &quot;datasets/visa_data//h1bvisa_part3.csv&quot; ## [4] &quot;datasets/visa_data//h1bvisa_part4.csv&quot; ## [5] &quot;datasets/visa_data//h1bvisa_part5.csv&quot; ## [6] &quot;datasets/visa_data//h1bvisa_part6.csv&quot; ## [7] &quot;datasets/visa_data//h1bvisa_part7.csv&quot; # Read all csv files in the folder and create a list of dataframes ldf &lt;- lapply(csv_list , read.csv) # Combine each dataframe in the list into a single dataframe visa_df &lt;- do.call(&quot;rbind&quot;, ldf) # str_split or string split is a great function to use. It breaks up a string based on a character. In this case we want to split our string into a list of cities and states which are split by a comma worksites = str_split(visa_df$WORKSITE, &quot;,&quot;, simplify = TRUE) head(worksites) ## [,1] [,2] ## [1,] &quot;ANN ARBOR&quot; &quot; MICHIGAN&quot; ## [2,] &quot;PLANO&quot; &quot; TEXAS&quot; ## [3,] &quot;JERSEY CITY&quot; &quot; NEW JERSEY&quot; ## [4,] &quot;DENVER&quot; &quot; COLORADO&quot; ## [5,] &quot;ST. LOUIS&quot; &quot; MISSOURI&quot; ## [6,] &quot;MIAMI&quot; &quot; FLORIDA&quot; # grab the second column which is just the states states = worksites[,2] head(states) ## [1] &quot; MICHIGAN&quot; &quot; TEXAS&quot; &quot; NEW JERSEY&quot; &quot; COLORADO&quot; &quot; MISSOURI&quot; ## [6] &quot; FLORIDA&quot; # Now we can use the trimws() function to trim the whitespace and get rid of the leading spaces states = trimws(states) # now add it to the dataframe visa_df$states &lt;- states ## Warning in instance$preRenderHook(instance): It seems your data is too big ## for client-side DataTables. You may consider server-side processing: https:// ## rstudio.github.io/DT/server.html 9.2 Full Time Positions What percentage is full time vs part time? # filter the data where there is data under FULL_TIME_POSITION (i.e. get rid of values that are NA) pos_df = filter(.data = visa_df, !is.na(FULL_TIME_POSITION)) # group the data by the FULL_TIME_POSITION pos_df = group_by(.data=pos_df, FULL_TIME_POSITION) # summarize the data based on the total number of recrods pos_df = summarise(.data = pos_df,total_records = length(lat)) # what does pos_df look like pos_df ## # A tibble: 2 x 2 ## FULL_TIME_POSITION total_records ## &lt;fct&gt; &lt;int&gt; ## 1 N 351146 ## 2 Y 296662 Alright, we have the total number of records for both Full time and Part Time position. What’s the percentage breakdown between the two? To answer this specific question, a pie chart might be useful. Luckily, a package called plotrix has a function called pie3D which can be used to accomplish this task. library(plotrix) ## Warning: package &#39;plotrix&#39; was built under R version 3.6.2 # create a list of our unique labels - Part time is first because it&#39;s the first row in pos_df (aka where the answer to full time position is N) lbls = c(&quot;Part time&quot;,&quot;Full time&quot;) # calculte the perdentage pcts = round(pos_df$total_records / sum(pos_df$total_records) * 100) # note that we use paste here and not paste0, remember that the 0 means 0 spaces between lbls = paste(lbls, pcts) lbls ## [1] &quot;Part time 54&quot; &quot;Full time 46&quot; # now let&#39;s add a % sign in lbls = paste(lbls,&quot;%&quot;, sep=&quot;&quot;) lbls ## [1] &quot;Part time 54%&quot; &quot;Full time 46%&quot; # create a list of the colors we want here cols = c(&quot;aquamarine3&quot;, &quot;indianred&quot;) pie3D(x=pos_df$total_records, labels=lbls, col = cols, explode=0, main = &quot;H1-B Visa Positions type&quot;) There are more part time positions rather than fulltime for this dataset. pie3D can be a useful, quick way to create a piechart. 9.3 Applications by State How does the number of total applications vary by state? What’s a good way to visualize this? We can use dplyr to separate out the total applications by state. We’ll have to use our states variable that we included with teh dataset above. # filter out the NA data state_df = filter(.data = visa_df, !is.na(states)) # group the dataframe by states state_df = group_by(.data = state_df, states) # create a summary per state by counting the total number of cases for each state state_df = summarise(.data = state_df, total_records = length(CASE_STATUS)) # Normalize the data by dividing by 1000 state_df$total_records &lt;- state_df$total_records/1000 #remember we can change the name of our columns if we want to colnames(state_df) &lt;- c(&quot;state&quot;,&quot;value&quot;) # use the treemap function from the treemap package to create the plot library(treemap) treemap(state_df, index=c(&quot;state&quot;), type=&quot;value&quot;, vSize = &quot;value&quot;, vColor=&quot;value&quot;, palette = &quot;RdBu&quot;, title=&quot;H1-B Visa Applications per State(thousands)&quot;, fontsize.title = 14 ) treemaps are great for visualizing data like this. Both the color and the total amount of space taken up in the image are correlated to the total amount of applications by state. Notice that the arguments for the treemap are a little different than ggplot2. treemap is not part of tidyverse, but still can be used with any data frame (as with most things in R). 9.4 Prevailing Wage by Location Let’s investigate another type of plot that R is capable of creating - a leaflet interactive plot. We’ll dive into this but first we’ll need to manipulate the data. Remember the lat/lon rounding we did? Let’s do that again only let’s round it down to 1/1000th decimal place. visa_df$lat = round(visa_df$lat,3) visa_df$lon = round(visa_df$lon,3) Now let’s filter our dataset, group it by lat and lon, and then take the mean of the PREVAILING WAGE variable. # filter out the NA values of the `lat` variable wage_df = filter(.data = visa_df, !is.na(lat)) # filter out the NA values of the `lon` variable wage_df = filter(.data = wage_df, !is.na(lon)) # filter for cases where the CASE_STATUS is CERTIFIED wage_df = filter(.data = wage_df, CASE_STATUS == &quot;CERTIFIED&quot;) # group by the lat AND lons (for times when the same company (aka same lat/lon) has multiple applications) wage_df = group_by(.data = wage_df, lat,lon) # summarize the data by taking the average PREVAILING WAGE wage_df = summarise(.data = wage_df, avg = mean(PREVAILING_WAGE)) # create the bins in which our color palette will have corresponding values bins &lt;- c(min(wage_df$avg),50000, 100000, 150000, 200000 ,max(wage_df$avg)) # create a custom color palette using pre-exisitng paletes and then coloring in the values based on the bins above # note that we use the premade color palette &quot;RdYlGn&quot; in R. pal &lt;- colorBin(&quot;RdYlGn&quot;, domain = wage_df$avg, bins = bins) # using leaflet which involves PIPING leaflet(data = wage_df) %&gt;% addTiles() %&gt;% setView(-99, 35, zoom = 4) %&gt;% addCircleMarkers( lat=wage_df$lat, lng=wage_df$lon, radius=sqrt(wage_df$avg)/20, color = ~pal(wage_df$avg), weight=1.5, opacity=0.8, popup= paste(&quot;Average Wage $&quot;, round(wage_df$avg/1000), &quot;k&quot;) ) There we have it, a beautiful and interactive map showing average wage for by location. leaflet is a powerful tool to visualize spatial data. The key here with leaflet is that with ggplot we can use the + sign to add additional arguments/functionality to a plot. With leaflet, we need to use the pipe operator - %&gt;%. Remember, the pipe operator can be though of as sending or passing along information. In this case we create a leaflet instance with leaflet(data=wage_df). We pipe that over to the leaflet function addTiles(). This creates the map. Then we set the view of the image as setView and then pipe that to the leaflet function as addCircleMarkers. This is the most advanced function with the leaflet package as we can add in a ton of functionality. An important note here is that for the color argument, we are using our pre-made color palette pal. 9.5 Recap Although we’ve spent a good bit of time with the most popular plotting package (ggplot2), there are other plotting packages in R that can be very useful The treemap package is useful for showing concentrations and distributions of a particular variable leaflet is a powerful interactive plotting package that’s great for spatial maps - leaflet uses the pipe operator %&gt;% R has many premade color palettes that are useful - more can be found here 9.6 Assignment What state is offering the highest average wage? What about the lowest? Create a treemap of the average prevailing wage by state. Where are the applications primarily coming from? Create a leaflet plot of the applications by location. First, round the lat/lon values to the 2nd decimal place. Then, plot your leaflet! You’ll want your resulting plots to look something like… "]
]
